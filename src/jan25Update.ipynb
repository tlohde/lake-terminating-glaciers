{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I've done so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import dask.dataframe as da\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "# from dem_utils import ArcticDEM\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "# import utils\n",
    "import cartopy.crs as ccrs\n",
    "import shapely\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.enums import Resampling\n",
    "import seaborn as sns\n",
    "# import odc.geo.xr\n",
    "from cycler import cycler\n",
    "prj = ccrs.Stereographic(\n",
    "    central_latitude=90,\n",
    "    central_longitude=-45,\n",
    "    true_scale_latitude=70\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def demote_coords_to_vars(ds: xr.Dataset,\n",
    "                        coords: str,\n",
    "                        var_name: str):\n",
    "    '''\n",
    "    messy onliner to for reorganizing dataset.\n",
    "    e.g. dataset with two variables: a (dims: x, y, t) and b (dims: x, y)\n",
    "    this function will convert it to a dataset with \n",
    "    dimensions x, y and add as many `a` variables as there dim `t` is long\n",
    "    '''\n",
    "    return xr.merge([\n",
    "        ds.drop_vars([coords, var_name]),\n",
    "        xr.merge(\n",
    "            [ds[var_name].isel({coords:i}).rename(ds[coords][i].item())\n",
    "            for i in range(len(ds[coords]))], compat='override').drop_vars(coords)]\n",
    "                    )\n",
    "\n",
    "def add_geom_mask(ds, geom, buffer=200):\n",
    "    # buffer geometry, with square ends\n",
    "    buff_geom = geom.buffer(buffer, cap_style=3)\n",
    "    \n",
    "    # empty array of same x, y dim shape as merged\n",
    "    arr = np.zeros((ds.sizes['y'], ds.sizes['x']))\n",
    "    \n",
    "    # rasterize\n",
    "    burned = rasterize(shapes=[(buff_geom, 1)],\n",
    "                       fill=0,\n",
    "                       out=arr,\n",
    "                       transform=ds.rio.transform())\n",
    "    \n",
    "    # merged rasterized with all other dataarrays\n",
    "    merged = xr.merge([ds, xr.DataArray(data=burned,\n",
    "                                        dims=['y','x'],\n",
    "                                        coords={'y': ds.y,\n",
    "                                                'x': ds.x}).rename('buffer_aoi')])\n",
    "\n",
    "    return merged\n",
    "\n",
    "class site():\n",
    "    def __init__(self,\n",
    "                 id: int,\n",
    "                 vars: list=['sec', 'dem', 'sample', 'coreg_meta', 'stable_terrain', 'centreline']):\n",
    "        \n",
    "        '''\n",
    "        convenience class for opening output files from directory id\n",
    "        id = id number of study site directory\n",
    "        vars = list of variables to include\n",
    "        returns the opened files\n",
    "        '''\n",
    "        \n",
    "        directories = glob('../data/id*')\n",
    "        directory = [d for d in directories if f'id{id}' in d]\n",
    "        assert len(directory) == 1, 'too many or not enough'\n",
    "        self.directory = directory[0]\n",
    "\n",
    "        self.paths = {\n",
    "            'sec': os.path.join(self.directory, 'sec.zarr'),\n",
    "            'dem': os.path.join(self.directory, 'stacked_coregd.zarr'),\n",
    "            'sample': os.path.join(self.directory, 'sec_sample.parquet'),\n",
    "            'coreg_meta': os.path.join(self.directory, 'coregistration_metadata.parquet'),\n",
    "            'stable_terrain': os.path.join(self.directory, 'stable_terrain_mask.tif'),\n",
    "            'centreline': os.path.join(self.directory, glob('line*.geojson', root_dir=self.directory)[0])\n",
    "            }\n",
    "\n",
    "        to_remove = []\n",
    "        for k, v in self.paths.items():\n",
    "            if os.path.exists(v):\n",
    "                continue\n",
    "            else:\n",
    "                to_remove.append(k)\n",
    "        \n",
    "        [self.paths.pop(k) for k in to_remove]\n",
    "                \n",
    "        self.open_funcs = {\n",
    "            '.tif': rio.open_rasterio,\n",
    "            '.zarr': xr.open_zarr,\n",
    "            '.parquet': pd.read_parquet,\n",
    "            '.geojson': gpd.read_file\n",
    "        }\n",
    "        \n",
    "        for var in [var for var in vars if var in self.paths.keys()]:\n",
    "            _, extension = os.path.splitext(self.paths[var])\n",
    "            setattr(self, var, self.open_funcs[extension](self.paths[var]))\n",
    "        \n",
    "        try:\n",
    "            self.sec = demote_coords_to_vars(self.sec, 'result', 'sec')\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface elevation change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab some metadata\n",
    "site_directories = glob('../data/id*')\n",
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "\n",
    "dem_ids = []\n",
    "dem_counts = []\n",
    "useful_dem_counts = []\n",
    "for d in site_directories:\n",
    "    df= pd.read_parquet(\n",
    "        os.path.join(d, 'coregistration_metadata.parquet')\n",
    "        )\n",
    "    dem_ids += df['to_reg_dem_id'].unique().tolist()\n",
    "    dem_counts.append(len(df['to_reg_dem_id'].unique()))\n",
    "    useful_dem_counts.append(((df['nmad_after'] < 2) & (df['median_after'].abs() < 1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of study sites, by location and type\n",
      "|                       |   geometry |\n",
      "|:----------------------|-----------:|\n",
      "| ('greenland', 'lake') |         14 |\n",
      "| ('greenland', 'land') |          9 |\n",
      "| ('iceland', 'lake')   |          7 |\n",
      "| ('iceland', 'land')   |          6 |\n",
      "\n",
      "total of 2153 _sections_ of DEMs used and coregistered (total of: 1629 tiles)\n",
      "each of the 36 study sites on average used 60(mean) 48 (median) DEMs. \n",
      "(where used means coregistered)\n",
      "\n",
      "Coregistered DEMs were removed from subsequent analyses if they failed to meet NMAD and MDOST of 2 m and ±1 m, respectively\n",
      "the site with the fewest/most DEMs used 2/148. mean/median: 48/36\n"
     ]
    }
   ],
   "source": [
    "# show the meta data\n",
    "print('number of study sites, by location and type')\n",
    "print(centrelines.groupby(['where', 'lake_land'])['geometry'].count().to_markdown())\n",
    "\n",
    "print(f'\\ntotal of {len(dem_ids)} _sections_ of DEMs used and coregistered (total of: {len(set(dem_ids))} tiles)')\n",
    "print(f'each of the 36 study sites on average used {np.mean(dem_counts):.0f}'\n",
    "      f'(mean) {np.median(dem_counts):.0f} (median) DEMs.',\n",
    "      '\\n(where used means coregistered)\\n')\n",
    "\n",
    "print('Coregistered DEMs were removed from subsequent analyses if they '\n",
    "      'failed to meet NMAD and MDOST of 2 m and ±1 m, respectively')\n",
    "print(f'the site with the fewest/most DEMs used {np.min(useful_dem_counts):.0f}/{np.max(useful_dem_counts):.0f}. '\n",
    "      f'mean/median: {np.mean(useful_dem_counts):.0f}/{np.median(useful_dem_counts):.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

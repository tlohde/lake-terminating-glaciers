{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s1 backscatter for lake ice cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `pro` env\n",
    "from dask.distributed import LocalCluster\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pystac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import rioxarray as rio\n",
    "import seaborn as sns\n",
    "from shapely.geometry import LineString, Point, box, Polygon\n",
    "import stackstac\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import xarray_sentinel as xrs\n",
    "import utils\n",
    "from geocube.api.core import make_geocube\n",
    "\n",
    "import os\n",
    "import sarsen\n",
    "import adlfs\n",
    "import requests\n",
    "import lakeIce_utils as liU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "\n",
    "basins = (gpd.read_file('../data/basins/Greenland_Basins_PS_v1.4.2.shp')\n",
    "          .dissolve('SUBREGION1'))\n",
    "centrelines = centrelines.sjoin(basins.drop(columns=['NAME', 'GL_TYPE']),\n",
    "                                how='left'\n",
    "                                ).rename(columns={'index_right': 'region'})\n",
    "\n",
    "lakes = gpd.read_file('../data/lake_areas.geojson')\n",
    "\n",
    "lakes = lakes.sjoin_nearest(centrelines)\n",
    "lakes = lakes.sort_values(by='id').drop(columns=['index_right', 'name', 'lake_land'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 8525.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(lakes.to_crs(4326).sample(1).itertuples()):\n",
    "    2+2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lakeIce_utils' from '/scratch/s1759665/paper2/src/lakeIce_utils.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(liU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = liU.Sentinel11(row=row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "li.get_unique_orbits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "            \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "            modifier=planetary_computer.sign_inplace,\n",
    "            )\n",
    "        \n",
    "search = catalog.search(collections=[f'cop-dem-glo-30'],\n",
    "                        intersects=li.geometry)\n",
    "\n",
    "items = search.item_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsg:32626'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li.s1_ds.attrs['crs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't need running again because saved output to: '../results/s1_lake_backscatter.parquet'\n",
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "medians = []\n",
    "ids = []\n",
    "for row in tqdm(lakes.to_crs(4326).sample(1).itertuples()):\n",
    "    \n",
    "    search = catalog.search(collections=['sentinel-1-rtc'],\n",
    "                            intersects=row.geometry)\n",
    "    \n",
    "    s1items = search.item_collection()\n",
    "    \n",
    "    # get most common projection\n",
    "    vals, cnts = np.unique([item.properties['proj:epsg'] for item in s1items] ,return_counts=True)\n",
    "    epsg = int(vals[np.argmax(cnts)])\n",
    "    \n",
    "    # stack & clip\n",
    "    ds = stackstac.stack(planetary_computer.sign(s1items),\n",
    "                        epsg=epsg,\n",
    "                        bounds_latlon=row.geometry.bounds)\n",
    "    \n",
    "    mask = (make_geocube(lakes.to_crs(4326).loc[lakes['id']==row.id],\n",
    "                          fill=np.nan,\n",
    "                          like=ds)['id']\n",
    "             .rename('mask'))\n",
    "    \n",
    "    # apply mask and convert to dB\n",
    "    ds_db = xr.where(mask==row.id,\n",
    "                     10 * np.log10(ds),\n",
    "                     np.nan)\n",
    "\n",
    "    median = (ds_db\n",
    "              .median(dim=['y','x'], skipna=True)\n",
    "              .rename('dB'))\n",
    "    \n",
    "    medians.append(median) # consider making this a future\n",
    "    ids.append(row.id)\n",
    "    \n",
    "with LocalCluster() as cluster:\n",
    "    client = cluster.get_client()\n",
    "    print(client.dashboard_link)    \n",
    "    computed_medians = dask.compute(*medians)\n",
    "    dfs = []\n",
    "    for m_ds, id in zip(computed_medians, ids):\n",
    "        _df = m_ds.to_dataframe()\n",
    "        _df['myid'] = id\n",
    "        dfs.append(_df)\n",
    "    \n",
    "    df = pd.concat(dfs).reset_index().set_index('time')\n",
    "    \n",
    "df.to_parquet('../results/s1_lake_backscatter.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wip: getting local incidence angle across sar image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using: \n",
    "- https://github.com/egagli/generate_sentinel1_local_incidence_angle_maps/blob/882b9940a843c6dc3040f992ad6bed14201a2f5c/generate_lia.py#L61\n",
    "- https://github.com/microsoft/PlanetaryComputerExamples/blob/main/tutorials/rtc-qualitative-assessment.ipynb\n",
    "- and sarsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incident_angles(aoi, ds):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dem\n",
    "def get_copernicus_dem(geom: Polygon,\n",
    "                        res: int = 30,\n",
    "                        ):\n",
    "    '''\n",
    "    get Copernicus Global DEM from planetary computer stac catalog\n",
    "    inputs:\n",
    "        geom - shapely geometry (polygon / box)\n",
    "        res - int: resolution of DEM (either 30, or 90, default 30)\n",
    "        rprj - bool: whether or not to reprojct the dem\n",
    "        prj - projection to reprject to\n",
    "        interp - whether or not to interpolate nans\n",
    "    returns: xarray instance of DEM\n",
    "    clipped to envelope of `geom`\n",
    "    if reprojected then not only clipped but also aligned\n",
    "    with nan's interpolated\n",
    "    '''\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=planetary_computer.sign_inplace,\n",
    "    )\n",
    "\n",
    "    search = catalog.search(collections=[f'cop-dem-glo-{res}'],\n",
    "                            intersects=geom.envelope)\n",
    "\n",
    "    items = search.item_collection()\n",
    "    if len(items) > 0:\n",
    "        dem = (stackstac.stack(\n",
    "            planetary_computer.sign(items))\n",
    "            .mean(dim='time', skipna=True)\n",
    "            .squeeze()\n",
    "            .rio.write_crs(4326)\n",
    "            .rio.clip_box(*geom.bounds)\n",
    "            )\n",
    "        \n",
    "    return dem\n",
    "\n",
    "dem = get_copernicus_dem(row.geometry)\n",
    "demprj = dem.rio.reproject_match(ds, nodata=np.nan)\n",
    "dem_prj = demprj.drop_vars(['epsg',\n",
    "                            'proj:transform',\n",
    "                            'proj:epsg',\n",
    "                            'proj:shape']).rio.write_crs(demprj.rio.crs)\n",
    "if dem_prj.y.diff('y').values[0] < 0:\n",
    "    dem_prj = dem_prj.isel(y=slice(None, None, -1))\n",
    "dem_prj.attrs['long_name'] = 'elevation'\n",
    "dem_prj.attrs['units'] = 'm'\n",
    "dem_prj = dem_prj.rename('dem').squeeze(drop=True)\n",
    "\n",
    "dem_ecef = sarsen.scene.convert_to_dem_ecef(dem_prj,\n",
    "                                            source_crs=demprj.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique relative orbits\n",
    "unique_relative_orbits = np.unique(ds['sat:relative_orbit'])\n",
    "folders = []\n",
    "idx = 0\n",
    "for orb in unique_relative_orbits:\n",
    "    \n",
    "    ids = ds[ds['sat:relative_orbit']==orb].id.values\n",
    "    \n",
    "    for id in ids:\n",
    "        \n",
    "        try:\n",
    "            rtc_item = catalog.get_collection('sentinel-1-rtc').get_item(id)\n",
    "            grd_item = pystac.read_file(rtc_item.get_single_link(\"derived_from\").target)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'an error of type {type(e)}: {e}')\n",
    "            \n",
    "        else:\n",
    "            grd_band = [grd_item.assets.get(band, None)\n",
    "                        for band in ['hh', 'hv', 'vh', 'vv']\n",
    "                        if band in grd_item.assets.keys()][0]\n",
    "            \n",
    "            folders.append(grd_band.href[53:-23])\n",
    "            break\n",
    "orb_dir = dict(zip(unique_relative_orbits, folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_folder(fs, bucket, folder):\n",
    "    # from https://github.com/bopen/sarsen/blob/main/notebooks/gamma_wrt_incidence_angle-S1-GRD-IW-RTC-South-of-Redmond.ipynb\n",
    "    for path, folders, files in fs.walk(f\"{bucket}/{folder}\"):\n",
    "        os.makedirs(path[len(bucket) + 1 :], exist_ok=True)\n",
    "        for f in files:\n",
    "            file_path = os.path.join(path, f)\n",
    "            lfile_path = file_path[len(bucket) + 1 :]\n",
    "            if not os.path.isfile(lfile_path):\n",
    "                fs.download(file_path, lfile_path + \"~\")\n",
    "                os.rename(lfile_path + \"~\", lfile_path)\n",
    "                \n",
    "def slant_to_ground(a, b):\n",
    "    xrs.slant_range_time_to_ground_range(a, b, coordinate_conversion=coord_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"s1-grd\"\n",
    "# token = planetary_computer.sas.get_token('sentinel1euwest', 's1-grd').token\n",
    "grd_fs = planetary_computer.get_adlfs_filesystem(account_name='sentinel1euwest',\n",
    "                                                 container_name='s1-grd')\n",
    "\n",
    "con_cli = planetary_computer.get_container_client(account_name='sentinel1euwest',\n",
    "                                                  container_name='s1-grd')\n",
    "angles = []\n",
    "for orb, folder in orb_dir.items():\n",
    "    mirror_folder(grd_fs, bucket, folder)\n",
    "    orbit_ecef, _ = sarsen.sentinel1.open_dataset_autodetect(folder, group='IW/HH/orbit')\n",
    "    coord_conv = [grp for grp in sarsen.sentinel1.open_dataset_autodetect(folder)[0].attrs['subgroups'] if 'coordinate_conversion' in grp][0]\n",
    "    coord_conversion, _ = sarsen.sentinel1.open_dataset_autodetect(folder, group=coord_conv)\n",
    "    acquisition = sarsen.apps.simulate_acquisition(dem_ecef,\n",
    "                                                orbit_ecef.position,\n",
    "                                                slant_range_time_to_ground_range=slant_to_ground,\n",
    "                                                correct_radiometry=True)\n",
    "    oriented_area = sarsen.scene.compute_dem_oriented_area(dem_ecef)\n",
    "    dem_normal = -oriented_area / np.sqrt(xr.dot(oriented_area, oriented_area, dims=\"axis\"))\n",
    "    orbit_interpolator = sarsen.orbit.OrbitPolyfitIterpolator.from_position(orbit_ecef.position)\n",
    "    position_ecef = orbit_interpolator.position()\n",
    "    velocity_ecef = orbit_interpolator.velocity()\n",
    "    acquisition = sarsen.geocoding.backward_geocode(dem_ecef, orbit_ecef.position, velocity_ecef)\n",
    "    slant_range = np.sqrt((acquisition.dem_distance**2).sum(dim=\"axis\"))\n",
    "    dem_direction = acquisition.dem_distance / slant_range\n",
    "    angle = np.arccos(xr.dot(dem_normal, dem_direction, dims=\"axis\"))\n",
    "    angles.append(angle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_ds = xr.concat(angles, dim='orbit')\n",
    "angle_ds['orbit'] = list(orb_dir.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_ds.plot(col='orbit', col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get s1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LocalCluster() as cluster:\n",
    "    client = cluster.get_client()\n",
    "    print(client.dashboard_link)    \n",
    "    computed_medians = dask.compute(*medians)\n",
    "    dfs = []\n",
    "    for m_ds, id in zip(computed_medians, ids):\n",
    "        _df = m_ds.to_dataframe()\n",
    "        _df['myid'] = id\n",
    "        dfs.append(_df)\n",
    "    \n",
    "    df = pd.concat(dfs).reset_index().set_index('time')\n",
    "    \n",
    "df.to_parquet('../results/s1_lake_backscatter.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../results/s1_lake_backscatter.parquet')\n",
    "df = df.merge(centrelines['SUBREGION1'], left_on='myid', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sat:relative_orbit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 1\n",
    "pol = 'hh'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[15,8])\n",
    "df.loc[(df['myid']==site) & (df['band']==pol)]['dB'].rolling('30d', center=True).median().plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.relplot(data=df.groupby(['myid', 'band', 'SUBREGION1'])['dB'].rolling('30d').median().reset_index(),\n",
    "                 x='time',\n",
    "                 y='dB',\n",
    "                 row='SUBREGION1',\n",
    "                 hue='SUBREGION1',\n",
    "                 style='myid',\n",
    "                 palette='tab10',\n",
    "                 col='band',\n",
    "                 col_order=['hh'],\n",
    "                 kind='line',\n",
    "                 aspect=2,\n",
    "                #  height=10\n",
    "                 )\n",
    "\n",
    "fg.set(ylim=(-22,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doy'] = df.index.day_of_year\n",
    "df['year'] = df.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = df.groupby(['myid', 'band', 'SUBREGION1'])['dB'].rolling('30d', min_periods=3, center=True).median().reset_index()\n",
    "smoothed['doy'] = smoothed['time'].dt.day_of_year\n",
    "smoothed['year'] = smoothed['time'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=smoothed.loc[\n",
    "    (smoothed['band'].isin(['hh']))\n",
    "    & (smoothed['year'].isin([2018, 2024]))\n",
    "    ],\n",
    "            x='doy',\n",
    "            y='dB',\n",
    "            hue='year',\n",
    "            col='SUBREGION1',\n",
    "            col_wrap=3,\n",
    "            # row='SUBREGION1',\n",
    "            kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

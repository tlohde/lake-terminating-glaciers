{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s1 backscatter for lake ice cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m product\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/geopandas/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeoseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeoSeries\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeodataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeoDataFrame\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m points_from_xy\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/geopandas/geoseries.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseGeometry\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeoPandasBase, _delegate_property\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _explore_geoseries\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_series\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/geopandas/base.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiPoint, box\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseGeometry\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compat \u001b[38;5;28;01mas\u001b[39;00m compat\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeometryArray, GeometryDtype, points_from_xy\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_geometry_type\u001b[39m(data):\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/geopandas/_compat.py:73\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# pyproj compat\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     HAS_PYPROJ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/pyproj/__init__.py:41\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_datadir\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     _pyproj_global_context_initialize,\n\u001b[1;32m     36\u001b[0m     set_use_global_context,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     show_versions,\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CRS  \u001b[38;5;66;03m# noqa: F401 pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     get_authorities,\n\u001b[1;32m     44\u001b[0m     get_codes,\n\u001b[1;32m     45\u001b[0m     get_units_map,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     DataDirError,\n\u001b[1;32m     49\u001b[0m     ProjError,\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/pyproj/crs/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis module interfaces with PROJ to produce a pythonic interface\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mto the coordinate reference system (CRS) information through the CRS\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mclass.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_crs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401  pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     CoordinateOperation,\n\u001b[1;32m      9\u001b[0m     CoordinateSystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     is_wkt,\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401  pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     CRS,\n\u001b[1;32m     18\u001b[0m     BoundCRS,\n\u001b[1;32m     19\u001b[0m     CompoundCRS,\n\u001b[1;32m     20\u001b[0m     CustomConstructorCRS,\n\u001b[1;32m     21\u001b[0m     DerivedGeographicCRS,\n\u001b[1;32m     22\u001b[0m     GeocentricCRS,\n\u001b[1;32m     23\u001b[0m     GeographicCRS,\n\u001b[1;32m     24\u001b[0m     ProjectedCRS,\n\u001b[1;32m     25\u001b[0m     VerticalCRS,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CRSError  \u001b[38;5;66;03m# noqa: F401  pylint: disable=unused-import\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pro/lib/python3.12/site-packages/pyproj/crs/crs.py:26\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Union\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_crs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     _CRS,\n\u001b[1;32m     14\u001b[0m     AreaOfUse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     is_wkt,\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cf1x8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     _GEOGRAPHIC_GRID_MAPPING_NAME_MAP,\n\u001b[1;32m     28\u001b[0m     _GRID_MAPPING_NAME_MAP,\n\u001b[1;32m     29\u001b[0m     _INVERSE_GEOGRAPHIC_GRID_MAPPING_NAME_MAP,\n\u001b[1;32m     30\u001b[0m     _INVERSE_GRID_MAPPING_NAME_MAP,\n\u001b[1;32m     31\u001b[0m     _horizontal_datum_from_params,\n\u001b[1;32m     32\u001b[0m     _try_list_if_string,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoordinate_operation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToWGS84Transformation\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoordinate_system\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cartesian2DCS, Ellipsoidal2DCS, VerticalCS\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1187\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use `pro` env\n",
    "from dask.distributed import LocalCluster\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rioxarray as rio\n",
    "import seaborn as sns\n",
    "from shapely.geometry import LineString, Point, box, Polygon\n",
    "import stackstac\n",
    "import xarray as xr\n",
    "import lakeIce_utils as liU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "\n",
    "basins = (gpd.read_file('../data/basins/Greenland_Basins_PS_v1.4.2.shp')\n",
    "          .dissolve('SUBREGION1'))\n",
    "centrelines = centrelines.sjoin(basins.drop(columns=['NAME', 'GL_TYPE']),\n",
    "                                how='left'\n",
    "                                ).rename(columns={'index_right': 'region'})\n",
    "\n",
    "lakes = gpd.read_file('../data/lake_areas.geojson')\n",
    "\n",
    "lakes = lakes.sjoin_nearest(centrelines)\n",
    "lakes = lakes.sort_values(by='id').drop(columns=['index_right', 'name', 'lake_land'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in lakes.to_crs(4326).loc[lakes['id']==6].itertuples():  # add back in tqdm if needed\n",
    "    2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lakeIce_utils' from '/scratch/s1759665/paper2/src/lakeIce_utils.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(liU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/sarsen/sentinel1.py:34: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  ds = xr.open_dataset(product_urlpath, group=group, chunks=chunks, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "li = liU.Sentinel1(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "july = li.dB.sel(time=li.dB.time.dt.month==7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "incident_angle_expanded = li.angle_ds.broadcast_like(li.dB.isel(band=0))\n",
    "\n",
    "# Flatten arrays for plotting, ensure dimensions match\n",
    "incident_angle_flat = np.degrees(incident_angle_expanded.values.flatten())\n",
    "july_hh = july.sel(band='hh').values.flatten()\n",
    "july_hv = july.sel(band='hv').values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering to avoid plotting NaN values or implementing additional checks\n",
    "idxs_hh = ~np.isnan(july_hh)\n",
    "idxs_hv = ~np.isnan(july_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.logical_and(idxs_hh, idxs_hv)\n",
    "valid_idxs = (idx * np.arange(0, len(idx)))[idx]\n",
    "sample_idxs = np.random.choice(valid_idxs, 1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(incident_angle_flat[sample_idxs], july_hh[sample_idxs], label='hh')\n",
    "ax.scatter(incident_angle_flat[sample_idxs], july_hv[sample_idxs], label='hv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't need running again because saved output to: '../results/s1_lake_backscatter.parquet'\n",
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "medians = []\n",
    "ids = []\n",
    "for row in tqdm(lakes.to_crs(4326).sample(1).itertuples()):\n",
    "    \n",
    "    search = catalog.search(collections=['sentinel-1-rtc'],\n",
    "                            intersects=row.geometry)\n",
    "    \n",
    "    s1items = search.item_collection()\n",
    "    \n",
    "    # get most common projection\n",
    "    vals, cnts = np.unique([item.properties['proj:epsg'] for item in s1items] ,return_counts=True)\n",
    "    epsg = int(vals[np.argmax(cnts)])\n",
    "    \n",
    "    # stack & clip\n",
    "    ds = stackstac.stack(planetary_computer.sign(s1items),\n",
    "                        epsg=epsg,\n",
    "                        bounds_latlon=row.geometry.bounds)\n",
    "    \n",
    "    mask = (make_geocube(lakes.to_crs(4326).loc[lakes['id']==row.id],\n",
    "                          fill=np.nan,\n",
    "                          like=ds)['id']\n",
    "             .rename('mask'))\n",
    "    \n",
    "    # apply mask and convert to dB\n",
    "    ds_db = xr.where(mask==row.id,\n",
    "                     10 * np.log10(ds),\n",
    "                     np.nan)\n",
    "\n",
    "    median = (ds_db\n",
    "              .median(dim=['y','x'], skipna=True)\n",
    "              .rename('dB'))\n",
    "    \n",
    "    medians.append(median) # consider making this a future\n",
    "    ids.append(row.id)\n",
    "    \n",
    "with LocalCluster() as cluster:\n",
    "    client = cluster.get_client()\n",
    "    print(client.dashboard_link)    \n",
    "    computed_medians = dask.compute(*medians)\n",
    "    dfs = []\n",
    "    for m_ds, id in zip(computed_medians, ids):\n",
    "        _df = m_ds.to_dataframe()\n",
    "        _df['myid'] = id\n",
    "        dfs.append(_df)\n",
    "    \n",
    "    df = pd.concat(dfs).reset_index().set_index('time')\n",
    "    \n",
    "df.to_parquet('../results/s1_lake_backscatter.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wip: getting local incidence angle across sar image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using: \n",
    "- https://github.com/egagli/generate_sentinel1_local_incidence_angle_maps/blob/882b9940a843c6dc3040f992ad6bed14201a2f5c/generate_lia.py#L61\n",
    "- https://github.com/microsoft/PlanetaryComputerExamples/blob/main/tutorials/rtc-qualitative-assessment.ipynb\n",
    "- and sarsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dem\n",
    "def get_copernicus_dem(geom: Polygon,\n",
    "                        res: int = 30,\n",
    "                        ):\n",
    "    '''\n",
    "    get Copernicus Global DEM from planetary computer stac catalog\n",
    "    inputs:\n",
    "        geom - shapely geometry (polygon / box)\n",
    "        res - int: resolution of DEM (either 30, or 90, default 30)\n",
    "        rprj - bool: whether or not to reprojct the dem\n",
    "        prj - projection to reprject to\n",
    "        interp - whether or not to interpolate nans\n",
    "    returns: xarray instance of DEM\n",
    "    clipped to envelope of `geom`\n",
    "    if reprojected then not only clipped but also aligned\n",
    "    with nan's interpolated\n",
    "    '''\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=planetary_computer.sign_inplace,\n",
    "    )\n",
    "\n",
    "    search = catalog.search(collections=[f'cop-dem-glo-{res}'],\n",
    "                            intersects=geom.envelope)\n",
    "\n",
    "    items = search.item_collection()\n",
    "    if len(items) > 0:\n",
    "        dem = (stackstac.stack(\n",
    "            planetary_computer.sign(items))\n",
    "            .mean(dim='time', skipna=True)\n",
    "            .squeeze()\n",
    "            .rio.write_crs(4326)\n",
    "            .rio.clip_box(*geom.bounds)\n",
    "            )\n",
    "        \n",
    "    return dem\n",
    "\n",
    "dem = get_copernicus_dem(row.geometry)\n",
    "demprj = dem.rio.reproject_match(ds, nodata=np.nan)\n",
    "dem_prj = demprj.drop_vars(['epsg',\n",
    "                            'proj:transform',\n",
    "                            'proj:epsg',\n",
    "                            'proj:shape']).rio.write_crs(demprj.rio.crs)\n",
    "if dem_prj.y.diff('y').values[0] < 0:\n",
    "    dem_prj = dem_prj.isel(y=slice(None, None, -1))\n",
    "dem_prj.attrs['long_name'] = 'elevation'\n",
    "dem_prj.attrs['units'] = 'm'\n",
    "dem_prj = dem_prj.rename('dem').squeeze(drop=True)\n",
    "\n",
    "dem_ecef = sarsen.scene.convert_to_dem_ecef(dem_prj,\n",
    "                                            source_crs=demprj.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique relative orbits\n",
    "unique_relative_orbits = np.unique(ds['sat:relative_orbit'])\n",
    "folders = []\n",
    "idx = 0\n",
    "for orb in unique_relative_orbits:\n",
    "    \n",
    "    ids = ds[ds['sat:relative_orbit']==orb].id.values\n",
    "    \n",
    "    for id in ids:\n",
    "        \n",
    "        try:\n",
    "            rtc_item = catalog.get_collection('sentinel-1-rtc').get_item(id)\n",
    "            grd_item = pystac.read_file(rtc_item.get_single_link(\"derived_from\").target)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'an error of type {type(e)}: {e}')\n",
    "            \n",
    "        else:\n",
    "            grd_band = [grd_item.assets.get(band, None)\n",
    "                        for band in ['hh', 'hv', 'vh', 'vv']\n",
    "                        if band in grd_item.assets.keys()][0]\n",
    "            \n",
    "            folders.append(grd_band.href[53:-23])\n",
    "            break\n",
    "orb_dir = dict(zip(unique_relative_orbits, folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_folder(fs, bucket, folder):\n",
    "    # from https://github.com/bopen/sarsen/blob/main/notebooks/gamma_wrt_incidence_angle-S1-GRD-IW-RTC-South-of-Redmond.ipynb\n",
    "    for path, folders, files in fs.walk(f\"{bucket}/{folder}\"):\n",
    "        os.makedirs(path[len(bucket) + 1 :], exist_ok=True)\n",
    "        for f in files:\n",
    "            file_path = os.path.join(path, f)\n",
    "            lfile_path = file_path[len(bucket) + 1 :]\n",
    "            if not os.path.isfile(lfile_path):\n",
    "                fs.download(file_path, lfile_path + \"~\")\n",
    "                os.rename(lfile_path + \"~\", lfile_path)\n",
    "                \n",
    "def slant_to_ground(a, b):\n",
    "    xrs.slant_range_time_to_ground_range(a, b, coordinate_conversion=coord_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"s1-grd\"\n",
    "# token = planetary_computer.sas.get_token('sentinel1euwest', 's1-grd').token\n",
    "grd_fs = planetary_computer.get_adlfs_filesystem(account_name='sentinel1euwest',\n",
    "                                                 container_name='s1-grd')\n",
    "\n",
    "con_cli = planetary_computer.get_container_client(account_name='sentinel1euwest',\n",
    "                                                  container_name='s1-grd')\n",
    "angles = []\n",
    "for orb, folder in orb_dir.items():\n",
    "    mirror_folder(grd_fs, bucket, folder)\n",
    "    orbit_ecef, _ = sarsen.sentinel1.open_dataset_autodetect(folder, group='IW/HH/orbit')\n",
    "    coord_conv = [grp for grp in sarsen.sentinel1.open_dataset_autodetect(folder)[0].attrs['subgroups'] if 'coordinate_conversion' in grp][0]\n",
    "    coord_conversion, _ = sarsen.sentinel1.open_dataset_autodetect(folder, group=coord_conv)\n",
    "    acquisition = sarsen.apps.simulate_acquisition(dem_ecef,\n",
    "                                                orbit_ecef.position,\n",
    "                                                slant_range_time_to_ground_range=slant_to_ground,\n",
    "                                                correct_radiometry=True)\n",
    "    oriented_area = sarsen.scene.compute_dem_oriented_area(dem_ecef)\n",
    "    dem_normal = -oriented_area / np.sqrt(xr.dot(oriented_area, oriented_area, dims=\"axis\"))\n",
    "    orbit_interpolator = sarsen.orbit.OrbitPolyfitIterpolator.from_position(orbit_ecef.position)\n",
    "    position_ecef = orbit_interpolator.position()\n",
    "    velocity_ecef = orbit_interpolator.velocity()\n",
    "    acquisition = sarsen.geocoding.backward_geocode(dem_ecef, orbit_ecef.position, velocity_ecef)\n",
    "    slant_range = np.sqrt((acquisition.dem_distance**2).sum(dim=\"axis\"))\n",
    "    dem_direction = acquisition.dem_distance / slant_range\n",
    "    angle = np.arccos(xr.dot(dem_normal, dem_direction, dims=\"axis\"))\n",
    "    angles.append(angle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_ds = xr.concat(angles, dim='orbit')\n",
    "angle_ds['orbit'] = list(orb_dir.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_ds.plot(col='orbit', col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get s1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LocalCluster() as cluster:\n",
    "    client = cluster.get_client()\n",
    "    print(client.dashboard_link)    \n",
    "    computed_medians = dask.compute(*medians)\n",
    "    dfs = []\n",
    "    for m_ds, id in zip(computed_medians, ids):\n",
    "        _df = m_ds.to_dataframe()\n",
    "        _df['myid'] = id\n",
    "        dfs.append(_df)\n",
    "    \n",
    "    df = pd.concat(dfs).reset_index().set_index('time')\n",
    "    \n",
    "df.to_parquet('../results/s1_lake_backscatter.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../results/s1_lake_backscatter.parquet')\n",
    "df = df.merge(centrelines['SUBREGION1'], left_on='myid', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sat:relative_orbit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 1\n",
    "pol = 'hh'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[15,8])\n",
    "df.loc[(df['myid']==site) & (df['band']==pol)]['dB'].rolling('30d', center=True).median().plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.relplot(data=df.groupby(['myid', 'band', 'SUBREGION1'])['dB'].rolling('30d').median().reset_index(),\n",
    "                 x='time',\n",
    "                 y='dB',\n",
    "                 row='SUBREGION1',\n",
    "                 hue='SUBREGION1',\n",
    "                 style='myid',\n",
    "                 palette='tab10',\n",
    "                 col='band',\n",
    "                 col_order=['hh'],\n",
    "                 kind='line',\n",
    "                 aspect=2,\n",
    "                #  height=10\n",
    "                 )\n",
    "\n",
    "fg.set(ylim=(-22,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doy'] = df.index.day_of_year\n",
    "df['year'] = df.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = df.groupby(['myid', 'band', 'SUBREGION1'])['dB'].rolling('30d', min_periods=3, center=True).median().reset_index()\n",
    "smoothed['doy'] = smoothed['time'].dt.day_of_year\n",
    "smoothed['year'] = smoothed['time'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=smoothed.loc[\n",
    "    (smoothed['band'].isin(['hh']))\n",
    "    & (smoothed['year'].isin([2018, 2024]))\n",
    "    ],\n",
    "            x='doy',\n",
    "            y='dB',\n",
    "            hue='year',\n",
    "            col='SUBREGION1',\n",
    "            col_wrap=3,\n",
    "            # row='SUBREGION1',\n",
    "            kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

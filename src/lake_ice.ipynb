{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s1 backscatter for lake ice cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lakeIce_utils' from '/scratch/s1759665/paper2/src/lakeIce_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use `pro` env\n",
    "from dask.distributed import LocalCluster\n",
    "from functools import reduce\n",
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import pandas as pd\n",
    "import rioxarray as rio\n",
    "import seaborn as sns\n",
    "import stackstac\n",
    "import xarray as xr\n",
    "import lakeIce_utils as liU\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import importlib\n",
    "importlib.reload(liU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "\n",
    "basins = (gpd.read_file('../data/basins/Greenland_Basins_PS_v1.4.2.shp')\n",
    "          .dissolve('SUBREGION1'))\n",
    "centrelines = centrelines.sjoin(basins.drop(columns=['NAME', 'GL_TYPE']),\n",
    "                                how='left'\n",
    "                                ).rename(columns={'index_right': 'region'})\n",
    "\n",
    "lakes = gpd.read_file('../data/lake_areas.geojson')\n",
    "\n",
    "lakes = lakes.sjoin_nearest(centrelines)\n",
    "lakes = (lakes\n",
    "            .sort_values(by='id')\n",
    "            .drop(columns=['index_right', 'name', 'lake_land'])\n",
    "            .to_crs(4326)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n",
      "/home/s1759665/micromamba/envs/pro/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1563: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already got incident angle ds...reading from .zarr\n"
     ]
    }
   ],
   "source": [
    "with LocalCluster(n_workers=8,\n",
    "                  threads_per_worker=2,\n",
    "                  memory_limit='1G',\n",
    "                  silence_logs=logging.ERROR) as cluster:\n",
    "    \n",
    "    client = cluster.get_client()\n",
    "    print(client.dashboard_link)\n",
    "    \n",
    "    li = liU.Sentinel1(lakes.loc[1], export=True, sample=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li.dBq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = li.dBq.attrs\n",
    "attrs['id'] = str(attrs['id'])\n",
    "li.dBq.attrs = attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li.dBq.to_parquet(li.quantile_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_parquet(f) for f in glob('../results/lakeIce/*_sample.parquet')])\n",
    "df = df.melt(['xy', 'time', 'sat:relative_orbit', 'angle', 'month', 'id', 'region'])\n",
    "df = df.rename(columns={\n",
    "    'variable': 'band',\n",
    "    'value': 'dB'\n",
    "})\n",
    "df['band'] = df['band'].str.replace('dB_', '')\n",
    "df['angle'] = np.degrees(df['angle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outliers (5th and 95th percentile) and ditch 'em before fitting model\n",
    "outliers = (df\n",
    " .groupby('band')\n",
    " .apply(lambda q: np.quantile(q['dB'], [0.05, 0.95]))\n",
    " .apply(pd.Series)\n",
    " .rename(columns={0: 'q02', 1: 'q98'})\n",
    ")\n",
    "\n",
    "idxs = []\n",
    "for band in outliers.index:\n",
    "    idx = (\n",
    "        (df['band'] == band)\n",
    "        &\n",
    "        (df['dB'] > outliers.loc[band, 'q02'])\n",
    "        &\n",
    "        (df['dB'] < outliers.loc[band, 'q98'])\n",
    "    )\n",
    "    idxs.append(idx)\n",
    "    \n",
    "idx = np.logical_or(*idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## backscatter dependence on angle by band and month\n",
    "lr = (df[idx].groupby(['band', 'month'])[['angle', 'dB']].apply(lambda q: pd.Series(linregress(x = q['angle'],\n",
    "                                                              y = q['dB'])))\n",
    "      .reset_index()\n",
    "      .rename(columns = {0:'slope',\n",
    "                         1:'intercept',\n",
    "                         2:'rvalue',\n",
    "                         3:'pvalue',\n",
    "                         4:'stderr'}))\n",
    "\n",
    "\n",
    "minang, maxang = df['angle'].agg(['min', 'max'])\n",
    "incident_angles = np.arange(minang//1, 1 + maxang//1)\n",
    "month_norm = Normalize(1, 12)\n",
    "\n",
    "print(lr.loc[\n",
    "    lr['slope'].abs().sort_values(ascending=False).index\n",
    "    ].to_markdown())\n",
    "\n",
    "band_style = {\n",
    "    'hh': ':',\n",
    "    'hv': '-'\n",
    "}\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for fit in lr.itertuples():\n",
    "    if fit.month == 6:\n",
    "        label = fit.band\n",
    "    else:\n",
    "        label = None\n",
    "    ax.plot(incident_angles,\n",
    "            incident_angles * fit.slope + fit.intercept,\n",
    "            c=plt.get_cmap('twilight')(month_norm(fit.month)),\n",
    "            ls=band_style[fit.band],\n",
    "            label=label)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "sm = ScalarMappable(month_norm, cmap='twilight')\n",
    "plt.colorbar(sm, ax=ax, label='month')\n",
    "\n",
    "ax.set(xlabel='Incidence Angle (degrees)',\n",
    "       ylabel='Backscatter (dB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## backscatter dependence on angle by BAND, only\n",
    "\n",
    "lr = (df[idx].groupby(['band'])[['angle', 'dB']].apply(lambda q: pd.Series(linregress(x = q['angle'],\n",
    "                                                              y = q['dB'])))\n",
    "      .reset_index()\n",
    "      .rename(columns = {0:'slope',\n",
    "                         1:'intercept',\n",
    "                         2:'rvalue',\n",
    "                         3:'pvalue',\n",
    "                         4:'stderr'}))\n",
    "\n",
    "print(lr.to_markdown())\n",
    "\n",
    "minang, maxang = df['angle'].agg(['min', 'max'])\n",
    "incident_angles = np.arange(minang//1, 1 + maxang//1)\n",
    "\n",
    "band_style = {\n",
    "    'hh': ':',\n",
    "    'hv': '-'\n",
    "}\n",
    "fig, ax = plt.subplots()\n",
    "for fit in lr.itertuples():    \n",
    "    ax.plot(incident_angles,\n",
    "            incident_angles * fit.slope + fit.intercept,\n",
    "            ls=band_style[fit.band],\n",
    "            label=fit.band)\n",
    "ax.legend()\n",
    "\n",
    "ax.set(xlabel='Incidence Angle (degrees)',\n",
    "       ylabel='Backscatter (dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't need running again because saved output to: '../results/s1_lake_backscatter.parquet'\n",
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "medians = []\n",
    "ids = []\n",
    "for row in tqdm(lakes.to_crs(4326).sample(1).itertuples()):\n",
    "    \n",
    "    search = catalog.search(collections=['sentinel-1-rtc'],\n",
    "                            intersects=row.geometry)\n",
    "    \n",
    "    s1items = search.item_collection()\n",
    "    \n",
    "    # get most common projection\n",
    "    vals, cnts = np.unique([item.properties['proj:epsg'] for item in s1items] ,return_counts=True)\n",
    "    epsg = int(vals[np.argmax(cnts)])\n",
    "    \n",
    "    # stack & clip\n",
    "    ds = stackstac.stack(planetary_computer.sign(s1items),\n",
    "                        epsg=epsg,\n",
    "                        bounds_latlon=row.geometry.bounds)\n",
    "    \n",
    "    mask = (make_geocube(lakes.to_crs(4326).loc[lakes['id']==row.id],\n",
    "                          fill=np.nan,\n",
    "                          like=ds)['id']\n",
    "             .rename('mask'))\n",
    "    \n",
    "    # apply mask and convert to dB\n",
    "    ds_db = xr.where(mask==row.id,\n",
    "                     10 * np.log10(ds),\n",
    "                     np.nan)\n",
    "\n",
    "    median = (ds_db\n",
    "              .median(dim=['y','x'], skipna=True)\n",
    "              .rename('dB'))\n",
    "    \n",
    "    medians.append(median) # consider making this a future\n",
    "    ids.append(row.id)\n",
    "    \n",
    "with LocalCluster() as cluster:\n",
    "    client = cluster.get_client()\n",
    "    print(client.dashboard_link)    \n",
    "    computed_medians = dask.compute(*medians)\n",
    "    dfs = []\n",
    "    for m_ds, id in zip(computed_medians, ids):\n",
    "        _df = m_ds.to_dataframe()\n",
    "        _df['myid'] = id\n",
    "        dfs.append(_df)\n",
    "    \n",
    "    df = pd.concat(dfs).reset_index().set_index('time')\n",
    "    \n",
    "df.to_parquet('../results/s1_lake_backscatter.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using: \n",
    "- https://github.com/egagli/generate_sentinel1_local_incidence_angle_maps/blob/882b9940a843c6dc3040f992ad6bed14201a2f5c/generate_lia.py#L61\n",
    "- https://github.com/microsoft/PlanetaryComputerExamples/blob/main/tutorials/rtc-qualitative-assessment.ipynb\n",
    "- and sarsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get s1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../results/s1_lake_backscatter.parquet')\n",
    "df = df.merge(centrelines['SUBREGION1'], left_on='myid', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.relplot(data=df.groupby(['myid', 'band', 'SUBREGION1'])['dB'].rolling('30d').median().reset_index(),\n",
    "                 x='time',\n",
    "                 y='dB',\n",
    "                 row='SUBREGION1',\n",
    "                 hue='SUBREGION1',\n",
    "                 style='myid',\n",
    "                 palette='tab10',\n",
    "                 col='band',\n",
    "                 col_order=['hh'],\n",
    "                 kind='line',\n",
    "                 aspect=2,\n",
    "                #  height=10\n",
    "                 )\n",
    "\n",
    "fg.set(ylim=(-22,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doy'] = df.index.day_of_year\n",
    "df['year'] = df.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = df.groupby(['myid', 'band', 'SUBREGION1'])['dB'].rolling('30d', min_periods=3, center=True).median().reset_index()\n",
    "smoothed['doy'] = smoothed['time'].dt.day_of_year\n",
    "smoothed['year'] = smoothed['time'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=smoothed.loc[\n",
    "    (smoothed['band'].isin(['hh']))\n",
    "    & (smoothed['year'].isin([2018, 2024]))\n",
    "    ],\n",
    "            x='doy',\n",
    "            y='dB',\n",
    "            hue='year',\n",
    "            col='SUBREGION1',\n",
    "            col_wrap=3,\n",
    "            # row='SUBREGION1',\n",
    "            kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

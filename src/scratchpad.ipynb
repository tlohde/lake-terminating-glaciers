{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "jason briner - long term perspectives of greenland ice sheet position\n",
    "- if current approx margin configuration is where it _generally_ is during interglacials then it would *make sense* that there are lots of overdeepenings just up-ice.\n",
    "- Lindbäck, K., R. Pettersson, A. L. Hubbard, S. H. Doyle, D. van As, A. B. Mikkelsen, and A. A. Fitzpatrick. 2015. Subglacial water drainage, storage and piracy beneath the Greenland ice sheet. Geophysical Research Letters 42:7606–14.\n",
    "see lindback references in ross et al., 2018\n",
    "- Lindbäck, K., R. Petterson, S. H. Doyle, C. Helanow, P. Jansson, S. S. Kristensen, L. Stenseng, R. Forsberg, and A. L. Hubbard. 2014. High-resolution ice thickness and bed topography of a land-terminating section of the Greenland ice sheet. Earth System Science Data 6:331–38.\n",
    "is there evidence of *preferential* erosion signature\n",
    "\n",
    "lake massu\n",
    "simon mudd, mikael attal - what are lakes? \n",
    "rivers **cannot** erode below base level.\n",
    "\n",
    "TODO\n",
    "send PN velocity figures and summary paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import pandas as pd\n",
    "import itslive\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import box\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imagery\n",
    "import xrspatial as xrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask dashboard: http://127.0.0.1:50288/status\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "print(f'dask dashboard: {client.dashboard_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import imagery\n",
    "import utils\n",
    "import get_velocity\n",
    "_ = importlib.reload(utils)\n",
    "_ = importlib.reload(get_velocity)\n",
    "_ = importlib.reload(imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = gpd.read_file('../data/terminus_boxes.geojson')\n",
    "sites = gpd.read_file('../data/potential_study_sites_v2.geojson',)\n",
    "sites['velocity'] = pd.Series(dtype=object)\n",
    "lines = gpd.read_file('../data/streams_v2.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = {}\n",
    "V[1] = get_velocity.CentreLiner(geo=lines.loc[1, 'geometry'],\n",
    "                                buff_dist=2_000,\n",
    "                                index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = []\n",
    "for k, v in V.items():\n",
    "    streams.append(v.tidy_stream)\n",
    "sites['streams'] = gpd.GeoSeries(streams, crs=3413)\n",
    "sites['streams'] = sites['streams'].astype(sites['geometry'].dtype)\n",
    "\n",
    "stream_gdf = gpd.GeoDataFrame(geometry=streams, crs=3413)\n",
    "# stream_gdf.to_file('../data/streams_v2.geojson')\n",
    "stream_gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmcrameri.cm as cmc\n",
    "def v_profile_plotter(self, ax):\n",
    "    _annual_v = (self.v_line_df.groupby(\n",
    "        ['cumul_dist', 'year']\n",
    "        )['v'].agg(['median',\n",
    "                    partial(median_abs_deviation,\n",
    "                            nan_policy='omit')])\n",
    "        .reset_index())\n",
    "    \n",
    "    _annual_v['y1'] = (_annual_v['median']\n",
    "                        + (1.4826 * _annual_v['median_abs_deviation'])\n",
    "    )\n",
    "    _annual_v['y2'] = (_annual_v['median']\n",
    "                        - (1.4826 * _annual_v['median_abs_deviation'])\n",
    "    )\n",
    "    norm = Normalize(*_annual_v['year'].agg(['min', 'max']))\n",
    "    cmap = cmc.batlow_r\n",
    "\n",
    "    for year in _annual_v['year'].unique():\n",
    "        _idx = _annual_v['year']==year\n",
    "        ax.plot(_annual_v.loc[_idx, 'cumul_dist']/1000,\n",
    "                _annual_v.loc[_idx, 'median'],\n",
    "                c=cmap(norm(year)))\n",
    "        \n",
    "        ax.fill_between(_annual_v.loc[_idx, 'cumul_dist']/1000,\n",
    "                        _annual_v.loc[_idx, 'y1'],\n",
    "                        _annual_v.loc[_idx, 'y2'],\n",
    "                        alpha=0.2,\n",
    "                        color=cmap(norm(year)),\n",
    "                        label=year)\n",
    "    plt.colorbar(ScalarMappable(cmap=cmap, norm=norm), ax=ax)\n",
    "    \n",
    "    ax.set(ylim=(0,None),\n",
    "           xlabel=('distance from terminus (km)'),\n",
    "           ylabel=('velocity (m/yr)'))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(V[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at underlying dodgy velocity images\n",
    "TODO look at GRIMpP and MEASUREs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- PN thinks that relative change is sufficient to *control* for variations in glacier geometry (read: width/size).\n",
    "- most interested in *relative* change of velocity over final few kilometers.\n",
    "    - i.e. \n",
    "\n",
    "- it all comes from the same raw processed v data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sites = gpd.read_file('../data/potential_study_sites_v1.geojson')\n",
    "study_sites = study_sites.loc[study_sites['notes'].isin(['yes', 'maybe'])]\n",
    "study_sites.reset_index(drop=True, inplace=True)\n",
    "study_sites_5k = study_sites.buffer(5_000).to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = imagery.get_annual_median_mosaic(\n",
    "    study_sites.loc[0,'geometry'],\n",
    "    buffer_dist=15_000,\n",
    "    src_crs=study_sites.crs,\n",
    "    target_crs=4326,\n",
    "    timeperiod='2023-01-01/2024-01-01',\n",
    "    months=[8,9],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xrs.multispectral.true_color(\n",
    "    *items.squeeze()\n",
    "    .transpose('band', 'y', 'x'))\n",
    " .plot.imshow(rgb='band')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "stackstac.stack(items, assets=['B04', 'B03', 'B02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrs.multispectral.true_color(*img.squeeze().transpose('band', 'y', 'x'),\n",
    "                             nodata=np.nan).plot.imshow(rgb='band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrs.multispectral.true_color(*img.squeeze().transpose('band', 'y', 'x'),\n",
    "                             nodata=np.nan).plot.imshow(rgb='band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = itslive.velocity_cubes.find_by_polygon(study_sites_5k.geometry[0])\n",
    "zarr_bounds = Polygon(z0[0]['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = study_sites_5k.loc[[0]].explore()\n",
    "gpd.GeoSeries([zarr_bounds], crs=4326).explore(m=m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

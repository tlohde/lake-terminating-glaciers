{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "jason briner - long term perspectives of greenland ice sheet position\n",
    "- if current approx margin configuration is where it _generally_ is during interglacials then it would *make sense* that there are lots of overdeepenings just up-ice.\n",
    "- Lindbäck, K., R. Pettersson, A. L. Hubbard, S. H. Doyle, D. van As, A. B. Mikkelsen, and A. A. Fitzpatrick. 2015. Subglacial water drainage, storage and piracy beneath the Greenland ice sheet. Geophysical Research Letters 42:7606–14.\n",
    "see lindback references in ross et al., 2018\n",
    "- Lindbäck, K., R. Petterson, S. H. Doyle, C. Helanow, P. Jansson, S. S. Kristensen, L. Stenseng, R. Forsberg, and A. L. Hubbard. 2014. High-resolution ice thickness and bed topography of a land-terminating section of the Greenland ice sheet. Earth System Science Data 6:331–38.\n",
    "is there evidence of *preferential* erosion signature\n",
    "\n",
    "lake massu\n",
    "simon mudd, mikael attal - what are lakes? \n",
    "rivers **cannot** erode below base level.\n",
    "\n",
    "TODO\n",
    "send PN velocity figures and summary paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd\n",
    "# import itslive\n",
    "import geopandas as gpd\n",
    "# from shapely.geometry import Polygon\n",
    "# from shapely import box\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.collections import LineCollection\n",
    "# from matplotlib.dates import date2num, DateFormatter, YearLocator\n",
    "# import seaborn as sns\n",
    "# import xrspatial as xrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import importlib\n",
    "# import imagery\n",
    "import utils\n",
    "import velocity_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = importlib.reload(utils)\n",
    "# _ = importlib.reload(velocity_helpers)\n",
    "# _ = importlib.reload(imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in lines, and lazily get velocity cubes, centrelines, and robust trends\n",
    "lines = gpd.read_file('../data/streams_v2.geojson')\n",
    "V = {}\n",
    "failed = []\n",
    "for row in tqdm(lines.sample(1).itertuples()):\n",
    "    print(f'working on #{row.Index}')\n",
    "    try:\n",
    "        V[row.Index] = velocity_helpers.CentreLiner(\n",
    "            geo=row.geometry,\n",
    "            buff_dist=3_000,\n",
    "            index=row.Index,\n",
    "            filter_cube=True,\n",
    "            get_annual_trends=True,\n",
    "            get_annual_median=False,\n",
    "            get_rgb=False)\n",
    "        display.clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        failed.append((row.Index, e))\n",
    "        print(f'#{row.Index} did not work because\\n{e}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute robust trends and export at the same time\n",
    "for k, v in tqdm(V.items()):\n",
    "    v.robust_trend['v_trend'].attrs = {'crs':3413,\n",
    "                                       'buffer':3000,\n",
    "                                       'ddt_range':('335d', '395d'),\n",
    "                                       'mad_n':5,\n",
    "                                       'date':str(pd.Timestamp.now()),\n",
    "                                       'centreline':v.tidy_stream.wkt,\n",
    "                                       'centreline_id':k}\n",
    "    \n",
    "    (v.robust_trend['v_trend']\n",
    "     .chunk(dic(zip(v.robust_trend['v_trend'].dims,\n",
    "                    v.robust_trend['v_trend'].shape)))\n",
    "     .to_zarr(f'../results/intermediate/velocity/robust_annual_trends/id{k}.zarr'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,15],\n",
    "                        nrows=5,\n",
    "                        ncols=3,\n",
    "                        sharex=True,\n",
    "                        sharey=True)\n",
    "\n",
    "for k_v, ax in zip(V.items(), axs.flat):\n",
    "    k, v = k_v\n",
    "    get_velocity.Plotters.rolling_median(v,\n",
    "                                         ('335d','395d'),\n",
    "                                         ax=ax,\n",
    "                                         ddt_bars=False,\n",
    "                                         **{'var': 'v',\n",
    "                                            'col': 'cumul_dist',\n",
    "                                            'window': '90d',\n",
    "                                            'vals':[1_000, 5_000]\n",
    "                                            })\n",
    "    _point = utils.shapely_reprojector(v.point, 3413, 4326)\n",
    "    \n",
    "    ax.set_title(f'#{k}: {_point.y:.2f}N {_point.x:.2f}W')\n",
    "\n",
    "axs.flat[-2].remove()\n",
    "axs.flat[-1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centreline_theil_slopes(df, **kwargs):\n",
    "    \n",
    "    _var = kwargs.get('var', 'v')\n",
    "    _x = kwargs.get('x', 'mid_date')\n",
    "    _date_range = kwargs.get('date_range', (pd.Timestamp('1900-01-01'),\n",
    "                                            pd.Timestamp.now()))\n",
    "    _ddt_range = kwargs.get('ddt_range', ('0d', '30d'))\n",
    "    _mad = kwargs.get('mad', 3)\n",
    "    \n",
    "    _df = df.loc[df[_x].between(*_date_range)]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((ds['date_dt'] > pd.Timedelta('335d')) & ((ds['date_dt'] <= pd.Timedelta('395d')))).compute()\n",
    "\n",
    "from scipy.stats.mstats import theilslopes\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = (ds.mid_date[idx] - ds.mid_date[idx].min()) / pd.Timedelta('365.25d')\n",
    "y = ds['v'][idx,50,50].compute()\n",
    "\n",
    "nan_idx = y.isnull()\n",
    "\n",
    "x = x[~nan_idx]\n",
    "y= y[~nan_idx]\n",
    "\n",
    "theil_result = theilslopes(y=y, x=x)\n",
    "lr_result = linregress(x=x, y=y)\n",
    "\n",
    "\n",
    "X = np.arange(0,30)\n",
    "theil_fit = (X * theil_result.slope) + theil_result.intercept\n",
    "lr_fit = (X * lr_result.slope) + lr_result.intercept\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y)\n",
    "\n",
    "ax.plot(X, theil_fit, c='r', label='theilslopes')\n",
    "ax.plot(X, lr_fit, c='g', label='lr')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8], nrows=5, ncols=3)\n",
    "# get_velocity.Plotters.date_dt_bars(V[13],\n",
    "#                                    ('1d','15d'),\n",
    "#                                    ax=ax,\n",
    "#                                    **{'vals':[5_000,1_000]})\n",
    "\n",
    "get_velocity.Plotters.rolling_median(V[13],\n",
    "                                     ('335d','395d'),\n",
    "                                     ax=ax,\n",
    "                                     ddt_bars=False,\n",
    "                                     **{'var': 'v',\n",
    "                                        'col': 'cumul_dist',\n",
    "                                        'window': '180d',\n",
    "                                        'vals':[1_000, 3_000, 5_000, 10_000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at underlying dodgy velocity images\n",
    "TODO look at GRIMpP and MEASUREs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- PN thinks that relative change is sufficient to *control* for variations in glacier geometry (read: width/size).\n",
    "- most interested in *relative* change of velocity over final few kilometers.\n",
    "    - i.e. \n",
    "\n",
    "- it all comes from the same raw processed v data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sites = gpd.read_file('../data/potential_study_sites_v1.geojson')\n",
    "study_sites = study_sites.loc[study_sites['notes'].isin(['yes', 'maybe'])]\n",
    "study_sites.reset_index(drop=True, inplace=True)\n",
    "study_sites_5k = study_sites.buffer(5_000).to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = imagery.get_annual_median_mosaic(\n",
    "    study_sites.loc[0,'geometry'],\n",
    "    buffer_dist=15_000,\n",
    "    src_crs=study_sites.crs,\n",
    "    target_crs=4326,\n",
    "    timeperiod='2023-01-01/2024-01-01',\n",
    "    months=[8,9],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xrs.multispectral.true_color(\n",
    "    *items.squeeze()\n",
    "    .transpose('band', 'y', 'x'))\n",
    " .plot.imshow(rgb='band')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "stackstac.stack(items, assets=['B04', 'B03', 'B02'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

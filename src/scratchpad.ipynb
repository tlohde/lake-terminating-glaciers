{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "import os\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "from dem_utils import ArcticDEM\n",
    "# from itertools import product\n",
    "# import dask\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "# import utils\n",
    "import cartopy.crs as ccrs\n",
    "import shapely\n",
    "\n",
    "prj = ccrs.Stereographic(\n",
    "    central_latitude=90,\n",
    "    central_longitude=-45,\n",
    "    true_scale_latitude=70\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('../data/id*/*.parquet')\n",
    "nmad_threshold = 2.0\n",
    "median_threshold = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = glob('../data/id*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in sites:\n",
    "    \n",
    "    sec = xr.open_zarr(os.path.join(site, 'sec.zarr'))\n",
    "    df = pd.read_parquet(os.path.join(site, 'coregistration_metadata.parquet'))\n",
    "    dems_used = sec.attrs['dem_ids']\n",
    "    num_dems_used = df['to_reg_dem_id'].isin(dems_used).sum()\n",
    "    should_idx =  ((df['median_after'].abs() < 1) & (df['nmad_after'] <2))\n",
    "    num_should_have_used = should_idx.sum()\n",
    "    dem_ids_should_use = set(df.loc[should_idx, 'to_reg_dem_id'].tolist())\n",
    "        \n",
    "    if num_dems_used != num_should_have_used:\n",
    "        print(site)\n",
    "        print(f'set equality: {set(dems_used) == dem_ids_should_use}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "        \n",
    "    df = pd.read_parquet(f)\n",
    "    _min, _max = df.median_after.agg(['min', 'max'])\n",
    "\n",
    "    old_idx = (\n",
    "            (df['nmad_after'] < nmad_threshold) \n",
    "            & (df['median_after'] < median_threshold)\n",
    "            )\n",
    "\n",
    "    new_idx = (\n",
    "            (df['nmad_after'] < nmad_threshold)\n",
    "            & (df['median_after'].abs() < median_threshold)\n",
    "            )\n",
    "    \n",
    "    if new_idx.sum() != old_idx.sum():\n",
    "        id = os.path.basename(os.path.dirname(f)).split('_')[0]\n",
    "        print(f'{id} // old: {old_idx.sum()} // new: {new_idx.sum()} // min/max median after: {_min:.2f}/{_max:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr('../data/id0_-138892x_-3197992y/stacked_coregd.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((ds['nmad_after'] < nmad_threshold) \n",
    "       & (np.abs(ds['median_after']) < median_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.compute().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 11\n",
    "directory = glob(f'../data/id{id}_*')[0]\n",
    "\n",
    "sec = xr.open_zarr(directory + '/sec.zarr')\n",
    "dem = xr.open_zarr(directory + '/stacked_coregd.zarr')\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2,\n",
    "                        subplot_kw={'projection':prj})\n",
    "\n",
    "sec['sec'].sel(result='slope').plot(ax=axs[0],\n",
    "                                    robust=True,\n",
    "                                    cmap='RdBu')\n",
    "\n",
    "sec['n'].plot(ax=axs[1])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.plot(*wkt.loads(sec.attrs['centreline']).coords.xy, c='k', ls=':')\n",
    "\n",
    "axs[0].set_title(f'{id}: slope')\n",
    "axs[1].set_title(f'{id}: n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = gpd.read_parquet('../data/arcticDEM/data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/indexes/ArcticDEM_Strip_Index_s2s041_gpqt/ArcticDEM_Strip_Index_s2s041.parquet')\n",
    "aoi = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"coordinates\":[[[-50.07572791949772,63.9206187393269],[-50.07572791949772,63.75],[-49.55,63.75],[-49.55,63.9206187393269],[-50.07572791949772,63.9206187393269]]],\"type\":\"Polygon\"}}]}\n",
    "aoi = shapely.geometry.shape(aoi['features'][0]['geometry'])\n",
    "selection = catalog.loc[catalog.intersects(aoi)]\n",
    "selection = selection.loc[selection['acqdate1'].dt.year == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/isortuarsuupSermia/'\n",
    "stack_path = glob('stack*', root_dir=directory)[0]\n",
    "sec_path = glob('sec*', root_dir=directory)[0]\n",
    "meta_file = glob('*.parquet', root_dir=directory)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join(directory, meta_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = xr.open_dataset(os.path.join(directory, stack_path), engine='zarr', decode_cf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = xr.open_dataset(os.path.join(directory, sec_path), engine='zarr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec.rio.write_grid_mapping(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(sec.rio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_along_line(fp: str,\n",
    "                        geom=False,\n",
    "                        var=False):\n",
    "    '''\n",
    "    reads in .zarr from file path\n",
    "    (i.e. the output of `dem_trends.py`, or output of `dem_stacking.py`)\n",
    "    \n",
    "    takes the centreline stored in .attrs['centreline']\n",
    "    densifies it (to a total of 100 vertices)\n",
    "    \n",
    "    and samples the dataset\n",
    "    (using .interp(), as opposed to .sel(method='nearest')\n",
    "    at those points.\n",
    "    \n",
    "    option to specify `var` for only selecting certain variables\n",
    "    from the dataset. e.g. `var='z'` when reading `stacked_coreg.zarr`\n",
    "    as this contains lots variables that only have a time component\n",
    "    \n",
    "    returning Dataset with dims `time`, `cumulative_distance`\n",
    "    \n",
    "    inputs: sec_file_path (str) \n",
    "    outputs xr.Dataset()\n",
    "    '''\n",
    "    \n",
    "    assert(os.path.isdir(fp)), 'invalid path'\n",
    "    with xr.open_dataset(fp, engine='zarr') as ds:\n",
    "        \n",
    "        if geom:\n",
    "            centreline = geom\n",
    "        else:\n",
    "            centreline = shapely.wkt.loads(ds.attrs['centreline'])\n",
    "        \n",
    "        # densify line\n",
    "        points = [centreline.interpolate(i/100, normalized=True)\n",
    "                    for i in range(0, 100)]\n",
    "        cumulative_distance = [centreline.project(p)/1000 for p in points]\n",
    "        gdf_points = (gpd.GeoDataFrame(geometry=list(points),\n",
    "                                        index=cumulative_distance,\n",
    "                                        crs=3413\n",
    "                                        ).rename_axis('cumulative_distance'))\n",
    "        \n",
    "        gdf_points['x'] = gdf_points['geometry'].x\n",
    "        gdf_points['y'] = gdf_points['geometry'].y\n",
    "        \n",
    "        # sample dataarrays\n",
    "        sampled = ds.interp(x=gdf_points['x'].to_xarray(),\n",
    "                            y=gdf_points['y'].to_xarray())\n",
    "        \n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sec['n'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec['sec'].sel(result='slope').plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (xr.open_dataset(os.path.join(directory, stack_path),\n",
    "                      engine='zarr')['z']\n",
    "      .chunk('auto')) as dems:\n",
    "\n",
    "        with LocalCluster() as cluster, cluster.get_client() as client:\n",
    "            dem2018 = dems.sel(time=dems.time.dt.year == 2018).coarsen({'x': 10, 'y':10}, boundary='trim').median()\n",
    "            dem2018 = dem2018.compute()\n",
    "            dem2018.plot(col='time')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(os.path.join(directory, stack_path),\n",
    "                     engine='zarr') as dems:\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems['nmad_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems.sel(time = (dems.time.dt.year == 2018)\n",
    "         & (dems.nmad_after < 2)\n",
    "         & (dems.median_after <= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems.sel(time=dems.time.dt.year==2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2018 = dems.sel(time=dems.time.dt.year == 2018).coarsen({'x':10, 'y':10}, boundary='trim').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open_rasterio('../data/isortuarsuupSermia/stable_terrain_mask.tif') as stable:\n",
    "    stable.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = catalog.to_crs(dems.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_intersection = catalog.loc[catalog.intersects(shapely.geometry.box(*dems.rio.bounds()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_intersection.loc[cat_intersection['acqdate1'].dt.year==2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cat_intersection.loc[cat_intersection['acqdate1'].dt.year==2018].plot(fc='none')\n",
    "ax.plot(*shapely.geometry.box(*dems.rio.bounds()).exterior.coords.xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dems['z']\n",
    " .median(dim='time')\n",
    " .coarsen({'x':10, 'y':10}, boundary='trim')\n",
    " .median()\n",
    " .plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems['z'].sel(time=dems.time.dt.year==2018).squeeze().coarsen({'x':10, 'y':10}, boundary='trim').median().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic([['greenland'],['iceland']], sharex=True, sharey=True)\n",
    "\n",
    "directory = '../data/id5_-226289x_-2968847y/'\n",
    "for directory in glob('../data/id*'):\n",
    "    id = directory.split('id')[1].split('_')[0]\n",
    "    \n",
    "    centreline_filepath = glob('*.geojson', root_dir=directory)\n",
    "    gdf = gpd.read_file(os.path.join(directory, centreline_filepath[0]))\n",
    "    where = gdf.loc[0, 'where']\n",
    "    \n",
    "    sec_filepath = glob('sec.zarr', root_dir=directory)\n",
    "    sec_filepath = os.path.join(directory, sec_filepath[0])\n",
    "    z_filepath = glob('stacked*', root_dir=directory)\n",
    "    z_filepath = os.path.join(directory, z_filepath[0])\n",
    "    \n",
    "    sec_along_line = sample_sec_along_line(sec_filepath)\n",
    "    z_along_line = sample_sec_along_line(z_filepath, var='z')\n",
    "    merged = xr.merge([sec_along_line.sel(result='slope').drop_vars('spatial_ref'),\n",
    "                    z_along_line.median(dim='time')])\n",
    "\n",
    "    merged[['z', 'sec']].to_dataframe().sort_values(by='z').plot(x='z', y='sec', label=id, ax=axs[where])\n",
    "    \n",
    "axs['greenland'].legend(fontsize=8, ncols=3, frameon=False, loc='upper right')\n",
    "axs['iceland'].legend(fontsize=8, ncols=2, frameon=False)\n",
    "\n",
    "axs['greenland'].set_title('greenland')\n",
    "axs['iceland'].set_title('iceland')\n",
    "\n",
    "axs['iceland'].set_xlabel('elevation (m)')\n",
    "axs['iceland'].set_ylabel('sec (m/yr)')\n",
    "axs['greenland'].set_ylabel('sec (m/yr)')\n",
    "\n",
    "# fig.savefig('../results/elevation_change/sec_against_z.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directory to centrelines geojson\n",
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "centrelines['directory'] = pd.Series()\n",
    "for line in centrelines.itertuples():\n",
    "    cntr = line.geometry.centroid\n",
    "    centrelines.loc[line.Index, 'directory'] = f'../data/id{line.Index}_{cntr.x:.0f}x_{cntr.y:.0f}y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(ds, id, ax, plot_err=False):\n",
    "    \n",
    "    ds['sec'].sel(result='slope').plot(ax=ax, label=id)\n",
    "    if plot_err:\n",
    "        ax.fill_between(\n",
    "            x=ds.cumulative_distance,\n",
    "            y1=ds['sec'].sel(result='high_slope').data,\n",
    "            y2=ds['sec'].sel(result='low_slope').data,\n",
    "            color='lightgrey')\n",
    "    ax.axhline(0, c='grey', lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "from adjustText import adjust_text\n",
    "from cycler import cycler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = 'greenland'\n",
    "\n",
    "colors = plt.get_cmap('tab20').colors\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "\n",
    "ax.set_prop_cycle(cycler(color=colors))\n",
    "\n",
    "axmap = fig.add_subplot(1,2,2, projection=prj)\n",
    "axmap.add_feature(cfeature.COASTLINE, edgecolor='lightgrey')\n",
    "centrelines.loc[centrelines['where']==where].plot(ax=axmap, color='k')\n",
    "gl = axmap.gridlines(crs=ccrs.PlateCarree(),\n",
    "                     draw_labels=True,\n",
    "                     y_inline=False)\n",
    "gl.rotate_labels=False\n",
    "\n",
    "gl.bottom_labels=True\n",
    "gl.left_labels=True\n",
    "gl.top_labels=False\n",
    "gl.right_labels=False\n",
    "gl.ylabel_style = {'rotation': 90}\n",
    "\n",
    "\n",
    "texts = []\n",
    "for i, row in enumerate(centrelines.loc[centrelines['where'] == where].itertuples()):\n",
    "    \n",
    "    sec_file = glob('sec.zarr', root_dir=row.directory)\n",
    "    assert len(sec_file) == 1, 'not enough / too many files'\n",
    "    sec_file_path = os.path.join(row.directory, sec_file[0])\n",
    "    \n",
    "    sampled = ArcticDEM.sample_along_line(sec_file_path)\n",
    "    \n",
    "    plot_result(sampled, row.Index, ax)\n",
    "    \n",
    "    \n",
    "    text = axmap.annotate(\n",
    "        text=row.Index,\n",
    "        xy=row.geometry.centroid.coords[0],\n",
    "        c=colors[i],\n",
    "        path_effects=[path_effects.withSimplePatchShadow(shadow_rgbFace='lightgrey',\n",
    "                                                                 alpha=0.9,\n",
    "                                                                 offset=(1,-1))])\n",
    "    texts.append(text)\n",
    "    \n",
    "_ = adjust_text(texts)\n",
    "\n",
    "# ax.legend(ncols=2, frameon=False)\n",
    "ax.set_title(None)\n",
    "ax.set_ylabel('surface elevation change (m/yr)')\n",
    "ax.set_xlabel('distance from terminus (km)')\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "axmap.set_axis_off()\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax.set_title(where)\n",
    "ax.set_xlim(right=10.4)\n",
    "\n",
    "fig.savefig(f'../results/elevation_change/{where}_sec.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, subplot_kw={'projection':prj})\n",
    "\n",
    "with LocalCluster() as c, c.get_client() as cli:\n",
    "    with xr.open_dataset('../data/id9_484789x_-1406074y/sec.zarr/',\n",
    "                         engine='zarr') as ds:\n",
    "        # counts = ds['z'].isnull().sum(dim=['x', 'y'])\n",
    "        ds['sec'].sel(result='slope').plot(robust=True, ax=axs[0], cbar_kwargs={'shrink':0.5})\n",
    "        ds['n'].plot(ax=axs[1], cbar_kwargs={'shrink':0.5})\n",
    "        cl = wkt.loads(ds.attrs['centreline'])    \n",
    "\n",
    "for ax in axs:\n",
    "    ax.plot(*cl.coords.xy, c='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_stat(df, stat, ax):\n",
    "    # df = get_meta_df(d)\n",
    "    after = f'{stat}_after'\n",
    "    before = f'{stat}_before'\n",
    "    for row in df.iterrows():\n",
    "        # print(row[0])\n",
    "        ax.annotate(\"\",\n",
    "                    xy=(row[1]['to_reg_acqdate1'], row[1][after]),\n",
    "                    xytext=(row[1]['to_reg_acqdate1'], row[1][before]),\n",
    "                    arrowprops=dict(arrowstyle='->'))\n",
    "    \n",
    "    minx, maxx = df['to_reg_acqdate1'].agg(['min','max'])\n",
    "    delta = pd.Timedelta('90d')\n",
    "    ax.set_xlim(minx-delta, maxx+delta)\n",
    "    ax.set_ylim(*df[[after, before]].melt()['value'].agg(['min','max']))\n",
    "    \n",
    "    ax.axhline(0, c='lightgrey', lw=0.5)\n",
    "    ax.axvline(df.ref_acqdate1.unique()[0], ls=':', c='k')\n",
    "    ax.set_ylabel(f'{stat} (m)')\n",
    "    for label in ax.get_xticklabels(which='major'):\n",
    "        label.set(rotation=30, horizontalalignment='center')\n",
    "\n",
    "def plot_coreg(df, ax):\n",
    "    # df = get_meta_df(d)\n",
    "    \n",
    "    plot_df = df[['median_after','median_before','nmad_after','nmad_before']].melt()\n",
    "    plot_df['when'] = plot_df['variable'].str.split('_').apply(lambda x: x[1])\n",
    "    plot_df['variable'] = plot_df['variable'].str.split('_').apply(lambda x: x[0])\n",
    "    sns.violinplot(data=plot_df,\n",
    "                   x='variable',\n",
    "                   y='value',\n",
    "                   hue='when',\n",
    "                   palette=sns.palettes.color_palette('colorblind')[-2:],\n",
    "                   hue_order=['before','after'],\n",
    "                   ax=ax)\n",
    "    ax.set_ylabel('metres')\n",
    "    ax.set_xlabel(None)\n",
    "    ax.axhline(0, c='lightgrey', lw=0.5, zorder=0)\n",
    "    sns.move_legend(ax, loc='best', title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/id8_607229x_-1847482y/'\n",
    "file = glob('stack*', root_dir=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach = False\n",
    "\n",
    "if beach:\n",
    "    with xr.open_dataset(os.path.join(directory, file[0]), engine='zarr') as ds:\n",
    "        2+2\n",
    "else:\n",
    "    with rio.open_rasterio('../data/id0_-138892x_-3197992y/padded_SETSM_s2s041_W1W1_20180709_10200100727D6100_1020010076EA9B00_2m_lsf_seg1.tif') as ds:\n",
    "        3+3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(os.path.join(directory, file[0]), engine='zarr')['z'].rio.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd\n",
    "# import itslive\n",
    "import geopandas as gpd\n",
    "# from shapely.geometry import Polygon\n",
    "# from shapely import box\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.collections import LineCollection\n",
    "# from matplotlib.dates import date2num, DateFormatter, YearLocator\n",
    "# import seaborn as sns\n",
    "# import xrspatial as xrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import importlib\n",
    "# import imagery\n",
    "import utils\n",
    "import velocity_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = importlib.reload(utils)\n",
    "# _ = importlib.reload(velocity_helpers)\n",
    "# _ = importlib.reload(imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in lines, and lazily get velocity cubes, centrelines, and robust trends\n",
    "lines = gpd.read_file('../data/streams_v2.geojson').to_crs(3413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = {}\n",
    "failed = []\n",
    "for row in tqdm(lines.sample(3).itertuples()):\n",
    "    print(f'working on #{row.Index}')\n",
    "    try:\n",
    "        V[row.Index] = velocity_helpers.CentreLiner(\n",
    "            geo=row.geometry,\n",
    "            buff_dist=500,\n",
    "            index=row.Index,\n",
    "            filter_cube=False,\n",
    "            get_robust_trend=True,\n",
    "            get_annual_median=False,\n",
    "            get_rgb=False,\n",
    "            )\n",
    "    except Exception as e:\n",
    "        failed.append((row.Index, e))\n",
    "        print(f'#{row.Index} did not work because\\n{e}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8],\n",
    "                        nrows=2,\n",
    "                        ncols=4,\n",
    "                        sharex=True,\n",
    "                        sharey=True)\n",
    "\n",
    "for k_v, ax in zip(V.items(), axs.flat):\n",
    "    k, v = k_v\n",
    "    velocity_helpers.Plotters.rolling_median(v,\n",
    "                                             ax=ax,\n",
    "                                         **{'var': 'v',\n",
    "                                            'ddt_range': ('335d','395d'),\n",
    "                                            'ddt_bars': False,\n",
    "                                            'col': 'cumul_dist',\n",
    "                                            'window': '90d',\n",
    "                                            'vals':[500, 1_000, 3_000, 5_000]\n",
    "                                            })\n",
    "    _point = utils.shapely_reprojector(v.point, 3413, 4326)\n",
    "    \n",
    "    ax.set_title(f'#{k}: {_point.y:.2f}N {_point.x:.2f}W\\n{lines.loc[k,\"name\"]}')\n",
    "    ax.minorticks_off()\n",
    "\n",
    "# axs.flat[-2].remove()\n",
    "axs.flat[-1].remove()\n",
    "\n",
    "now = pd.Timestamp.now().strftime('%y%m%d_%H%M')+ '_'\n",
    "directory = '../../GitHub/diary/journal_figures'\n",
    "filename = 'iceland_outlets_annual_v.png'\n",
    "fig.savefig(directory + now + filename, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centreline_theil_slopes(df, **kwargs):\n",
    "    \n",
    "    _var = kwargs.get('var', 'v')\n",
    "    _x = kwargs.get('x', 'mid_date')\n",
    "    _date_range = kwargs.get('date_range', (pd.Timestamp('1900-01-01'),\n",
    "                                            pd.Timestamp.now()))\n",
    "    _ddt_range = kwargs.get('ddt_range', ('0d', '30d'))\n",
    "    _mad = kwargs.get('mad', 3)\n",
    "    \n",
    "    _df = df.loc[df[_x].between(*_date_range)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((ds['date_dt'] > pd.Timedelta('335d')) & ((ds['date_dt'] <= pd.Timedelta('395d')))).compute()\n",
    "\n",
    "from scipy.stats.mstats import theilslopes\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = (ds.mid_date[idx] - ds.mid_date[idx].min()) / pd.Timedelta('365.25d')\n",
    "y = ds['v'][idx,50,50].compute()\n",
    "\n",
    "nan_idx = y.isnull()\n",
    "\n",
    "x = x[~nan_idx]\n",
    "y= y[~nan_idx]\n",
    "\n",
    "theil_result = theilslopes(y=y, x=x)\n",
    "lr_result = linregress(x=x, y=y)\n",
    "\n",
    "\n",
    "X = np.arange(0,30)\n",
    "theil_fit = (X * theil_result.slope) + theil_result.intercept\n",
    "lr_fit = (X * lr_result.slope) + lr_result.intercept\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y)\n",
    "\n",
    "ax.plot(X, theil_fit, c='r', label='theilslopes')\n",
    "ax.plot(X, lr_fit, c='g', label='lr')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8], nrows=5, ncols=3)\n",
    "# get_velocity.Plotters.date_dt_bars(V[13],\n",
    "#                                    ('1d','15d'),\n",
    "#                                    ax=ax,\n",
    "#                                    **{'vals':[5_000,1_000]})\n",
    "\n",
    "get_velocity.Plotters.rolling_median(V[13],\n",
    "                                     ('335d','395d'),\n",
    "                                     ax=ax,\n",
    "                                     ddt_bars=False,\n",
    "                                     **{'var': 'v',\n",
    "                                        'col': 'cumul_dist',\n",
    "                                        'window': '180d',\n",
    "                                        'vals':[1_000, 3_000, 5_000, 10_000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at underlying dodgy velocity images\n",
    "TODO look at GRIMpP and MEASUREs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- PN thinks that relative change is sufficient to *control* for variations in glacier geometry (read: width/size).\n",
    "- most interested in *relative* change of velocity over final few kilometers.\n",
    "    - i.e. \n",
    "\n",
    "- it all comes from the same raw processed v data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sites = gpd.read_file('../data/potential_study_sites_v1.geojson')\n",
    "study_sites = study_sites.loc[study_sites['notes'].isin(['yes', 'maybe'])]\n",
    "study_sites.reset_index(drop=True, inplace=True)\n",
    "study_sites_5k = study_sites.buffer(5_000).to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = imagery.get_annual_median_mosaic(\n",
    "    study_sites.loc[0,'geometry'],\n",
    "    buffer_dist=15_000,\n",
    "    src_crs=study_sites.crs,\n",
    "    target_crs=4326,\n",
    "    timeperiod='2023-01-01/2024-01-01',\n",
    "    months=[8,9],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xrs.multispectral.true_color(\n",
    "    *items.squeeze()\n",
    "    .transpose('band', 'y', 'x'))\n",
    " .plot.imshow(rgb='band')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "stackstac.stack(items, assets=['B04', 'B03', 'B02'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "from dem_utils import ArcticDEM\n",
    "from itertools import product\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems = glob('../data/id1_*/padded*.tiff')\n",
    "masks = glob('../data/id1_*/mask*.tiff')\n",
    "coregd = glob('../data/id1_*/coregd*')\n",
    "zarrfile = glob('../data/id1_*/*.zarr')\n",
    "# line = glob('../data/id2_*/*.geojson')\n",
    "# line = gpd.read_file(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1759665/micromamba/envs/paper2/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37429 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()\n",
    "\n",
    "with xr.open_dataset(zarrfile[0],\n",
    "                     engine='zarr', \n",
    "                     ) as ds:\n",
    "    \n",
    "    ds = ds['z'].chunk(chunks={'y': len(ds.y) // 4,\n",
    "                                'x': len(ds.x) // 4})\n",
    "    \n",
    "    downsampled = ArcticDEM.downsample(ds, factor=10)\n",
    "    \n",
    "    downsampled = downsampled.chunk(\n",
    "        {'time': -1,\n",
    "            'y': 'auto',\n",
    "            'x': 'auto'}\n",
    "        )\n",
    "\n",
    "    trend = utils.Trends.make_robust_trend(downsampled,\n",
    "                                            inp_core_dim='time')\n",
    "\n",
    "    trend = trend.rename('sec')\n",
    "    \n",
    "    trend.attrs = {'description': '''\n",
    "        theilslope estimates of surface elevation change (sec)\n",
    "        high_slope and low_slope are the 0.95 confidence interval\n",
    "        '''}\n",
    "    \n",
    "    trend = trend.rio.write_crs(downsampled.rio.crs,\n",
    "                                        'spatial_ref')\n",
    "\n",
    "client.shutdown()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = xr.open_dataset('../data/id1_6685x_-3188046y/sec.zarr/', engine='zarr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "CRSError",
     "evalue": "Invalid projection: : (Internal Proj Error: proj_create: unrecognized format / unknown name)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCRSError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_mapping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/paper2/lib/python3.12/site-packages/rioxarray/rioxarray.py:371\u001b[0m, in \u001b[0;36mXRasterBase.set_crs\u001b[0;34m(self, input_crs, inplace)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_crs\u001b[39m(\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_crs: Any, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    354\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[xarray\u001b[38;5;241m.\u001b[39mDataset, xarray\u001b[38;5;241m.\u001b[39mDataArray]:\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    Set the CRS value for the Dataset/DataArray without modifying\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    the dataset/data array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        Dataset with crs attribute.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     crs \u001b[38;5;241m=\u001b[39m \u001b[43mcrs_from_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_crs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obj(inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m    373\u001b[0m     obj\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39m_crs \u001b[38;5;241m=\u001b[39m crs\n",
      "File \u001b[0;32m~/micromamba/envs/paper2/lib/python3.12/site-packages/rioxarray/crs.py:42\u001b[0m, in \u001b[0;36mcrs_from_user_input\u001b[0;34m(crs_input)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# use pyproj for edge cases\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m crs \u001b[38;5;241m=\u001b[39m \u001b[43mCRS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrs_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(rasterio\u001b[38;5;241m.\u001b[39m__gdal_version__) \u001b[38;5;241m>\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mcrs\u001b[38;5;241m.\u001b[39mCRS\u001b[38;5;241m.\u001b[39mfrom_wkt(crs\u001b[38;5;241m.\u001b[39mto_wkt())\n",
      "File \u001b[0;32m~/micromamba/envs/paper2/lib/python3.12/site-packages/pyproj/crs/crs.py:501\u001b[0m, in \u001b[0;36mCRS.from_user_input\u001b[0;34m(cls, value, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/paper2/lib/python3.12/site-packages/pyproj/crs/crs.py:348\u001b[0m, in \u001b[0;36mCRS.__init__\u001b[0;34m(self, projparams, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m=\u001b[39m projparams\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m=\u001b[39m \u001b[43m_CRS\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/paper2/lib/python3.12/site-packages/pyproj/_crs.pyx:2378\u001b[0m, in \u001b[0;36mpyproj._crs._CRS.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCRSError\u001b[0m: Invalid projection: : (Internal Proj Error: proj_create: unrecognized format / unknown name)"
     ]
    }
   ],
   "source": [
    "trends.rio.set_crs(trends[trends.rio.grid_mapping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(downsampled.time)):\n",
    "    fig, ax = plt.subplots()\n",
    "    downsampled[i,:,:].plot(ax=ax)\n",
    "    ax.set_title(f'{downsampled.time[i].dt.year.item()}/{downsampled.time[i].dt.month.item()}/{downsampled.time[i].dt.day.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mtrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_crs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgrid_mapping_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Write the CRS to the dataset in a CF compliant manner.\n",
      "\n",
      ".. warning:: The grid_mapping attribute is written to the encoding.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input_crs: Any\n",
      "    Anything accepted by `rasterio.crs.CRS.from_user_input`.\n",
      "grid_mapping_name: str, optional\n",
      "    Name of the grid_mapping coordinate to store the CRS information in.\n",
      "    Default is the grid_mapping name of the dataset.\n",
      "inplace: bool, optional\n",
      "    If True, it will write to the existing dataset. Default is False.\n",
      "\n",
      "Returns\n",
      "-------\n",
      ":obj:`xarray.Dataset` | :obj:`xarray.DataArray`:\n",
      "    Modified dataset with CF compliant CRS information.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Write the CRS of the current `xarray` object:\n",
      "\n",
      ">>> raster.rio.write_crs(\"epsg:4326\", inplace=True)\n",
      "\n",
      "Write the CRS on a copy:\n",
      "\n",
      ">>> raster = raster.rio.write_crs(\"epsg:4326\")\n",
      "\u001b[0;31mFile:\u001b[0m      ~/micromamba/envs/paper2/lib/python3.12/site-packages/rioxarray/rioxarray.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "trends.rio.write_crs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mtrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_crs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Set the CRS value for the Dataset/DataArray without modifying\n",
      "the dataset/data array.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input_crs: object\n",
      "    Anything accepted by `rasterio.crs.CRS.from_user_input`.\n",
      "inplace: bool, optional\n",
      "    If True, it will write to the existing dataset. Default is False.\n",
      "\n",
      "Returns\n",
      "-------\n",
      ":obj:`xarray.Dataset` | :obj:`xarray.DataArray`:\n",
      "    Dataset with crs attribute.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/micromamba/envs/paper2/lib/python3.12/site-packages/rioxarray/rioxarray.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "trends.rio.set_crs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems = []\n",
    "attrs = []\n",
    "for f in coregd:\n",
    "    with rio.open_rasterio(f, chunks='auto') as ds:\n",
    "        \n",
    "        if 'to_reg_acqdate1' in ds.attrs.keys():\n",
    "            _acqdate1 = pd.to_datetime(ds.attrs['to_reg_acqdate1'])\n",
    "        else:\n",
    "            _acqdate1 = pd.to_datetime(ds.attrs['ref_acqdate1'])\n",
    "            \n",
    "        time_index = xr.DataArray(\n",
    "            data=_acqdate1, # [pd.to_datetime(ds.attrs['to_register_date'], format=\"%Y-%m-%d\")],\n",
    "            dims=['band'],\n",
    "            coords={'band':[1]})\n",
    "        ds['time'] = time_index\n",
    "        ds = (ds.swap_dims({'band': 'time'})\n",
    "              .drop_vars('band')\n",
    "              .rename('z')\n",
    "              )\n",
    "        \n",
    "        if '_FillValue' in ds.attrs.keys():\n",
    "            fill_value = ds.attrs['_FillValue']\n",
    "            ds = xr.where(ds!=fill_value, ds, np.nan, keep_attrs=True)\n",
    "            ds.attrs['_FillValue'] = np.nan\n",
    "            dems.append(ds)\n",
    "        else:\n",
    "            ds.attrs['_FillValue'] = np.nan\n",
    "            dems.append(ds)\n",
    "        \n",
    "        attrs.append(ds.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.DataFrame(attrs)\n",
    "\n",
    "# drop some unwanted columns\n",
    "meta_df.drop(columns=['AREA_OR_POINT', 'scale_factor', 'add_offset',\n",
    "                      '_FillValue', 'long_name', 'to_reg_catalogid1',\n",
    "                      'ref_catalogid1', 'to_reg_catalogid2', 'ref_catalogid2'],\n",
    "            errors='ignore',\n",
    "            inplace=True)\n",
    "\n",
    "# add boolean column for is reference\n",
    "meta_df['is_reference'] = meta_df['to_reg_acqdate1'].isnull()\n",
    "\n",
    "# copy/duplicate ref_/to_reg data for reference DEM\n",
    "for col in meta_df.columns:\n",
    "    if 'ref' in col:\n",
    "        new_col = col.replace('ref_', 'to_reg_')\n",
    "        meta_df.loc[meta_df['is_reference'], new_col] = meta_df.loc[meta_df['is_reference'], col]\n",
    "\n",
    "meta_df = meta_df.set_index(pd.to_datetime(meta_df['to_reg_acqdate1'].rename('time')))\n",
    "\n",
    "# add additional metadata\n",
    "meta_df.attrs = {\n",
    "    'processed by': 'tlohde',\n",
    "    'processed on': pd.Timestamp.now().strftime('%Y/%m/%d %H:%M')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demstack = xr.concat(dems, dim='time', combine_attrs='drop').sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demstack = xr.merge([demstack,\n",
    "                     meta_df.to_xarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demstack.attrs = {\n",
    "    'processed by': 'tlohde',\n",
    "    'processed on': pd.Timestamp.now().strftime('%Y/%m/%d %H:%M'),\n",
    "    'centreline': gpd.read_file('../data/id1_6685x_-3188046y/line_6685x_-3188046y.geojson').loc[0,'geometry'].wkt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "jason briner - long term perspectives of greenland ice sheet position\n",
    "- if current approx margin configuration is where it _generally_ is during interglacials then it would *make sense* that there are lots of overdeepenings just up-ice.\n",
    "- Lindbäck, K., R. Pettersson, A. L. Hubbard, S. H. Doyle, D. van As, A. B. Mikkelsen, and A. A. Fitzpatrick. 2015. Subglacial water drainage, storage and piracy beneath the Greenland ice sheet. Geophysical Research Letters 42:7606–14.\n",
    "see lindback references in ross et al., 2018\n",
    "- Lindbäck, K., R. Petterson, S. H. Doyle, C. Helanow, P. Jansson, S. S. Kristensen, L. Stenseng, R. Forsberg, and A. L. Hubbard. 2014. High-resolution ice thickness and bed topography of a land-terminating section of the Greenland ice sheet. Earth System Science Data 6:331–38.\n",
    "is there evidence of *preferential* erosion signature\n",
    "\n",
    "lake massu\n",
    "simon mudd, mikael attal - what are lakes? \n",
    "rivers **cannot** erode below base level.\n",
    "\n",
    "TODO\n",
    "send PN velocity figures and summary paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../data/id1_6685x_-3188046y/stacked_coregd.zarr/', engine='zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ds['z'].polyfit(dim='time', deg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd\n",
    "# import itslive\n",
    "import geopandas as gpd\n",
    "# from shapely.geometry import Polygon\n",
    "# from shapely import box\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.collections import LineCollection\n",
    "# from matplotlib.dates import date2num, DateFormatter, YearLocator\n",
    "# import seaborn as sns\n",
    "# import xrspatial as xrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import importlib\n",
    "# import imagery\n",
    "import utils\n",
    "import velocity_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = importlib.reload(utils)\n",
    "# _ = importlib.reload(velocity_helpers)\n",
    "# _ = importlib.reload(imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in lines, and lazily get velocity cubes, centrelines, and robust trends\n",
    "lines = gpd.read_file('../data/streams_v2.geojson').to_crs(3413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = {}\n",
    "failed = []\n",
    "for row in tqdm(lines.sample(3).itertuples()):\n",
    "    print(f'working on #{row.Index}')\n",
    "    try:\n",
    "        V[row.Index] = velocity_helpers.CentreLiner(\n",
    "            geo=row.geometry,\n",
    "            buff_dist=500,\n",
    "            index=row.Index,\n",
    "            filter_cube=False,\n",
    "            get_robust_trend=True,\n",
    "            get_annual_median=False,\n",
    "            get_rgb=False,\n",
    "            )\n",
    "    except Exception as e:\n",
    "        failed.append((row.Index, e))\n",
    "        print(f'#{row.Index} did not work because\\n{e}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8],\n",
    "                        nrows=2,\n",
    "                        ncols=4,\n",
    "                        sharex=True,\n",
    "                        sharey=True)\n",
    "\n",
    "for k_v, ax in zip(V.items(), axs.flat):\n",
    "    k, v = k_v\n",
    "    velocity_helpers.Plotters.rolling_median(v,\n",
    "                                             ax=ax,\n",
    "                                         **{'var': 'v',\n",
    "                                            'ddt_range': ('335d','395d'),\n",
    "                                            'ddt_bars': False,\n",
    "                                            'col': 'cumul_dist',\n",
    "                                            'window': '90d',\n",
    "                                            'vals':[500, 1_000, 3_000, 5_000]\n",
    "                                            })\n",
    "    _point = utils.shapely_reprojector(v.point, 3413, 4326)\n",
    "    \n",
    "    ax.set_title(f'#{k}: {_point.y:.2f}N {_point.x:.2f}W\\n{lines.loc[k,\"name\"]}')\n",
    "    ax.minorticks_off()\n",
    "\n",
    "# axs.flat[-2].remove()\n",
    "axs.flat[-1].remove()\n",
    "\n",
    "now = pd.Timestamp.now().strftime('%y%m%d_%H%M')+ '_'\n",
    "directory = '../../GitHub/diary/journal_figures'\n",
    "filename = 'iceland_outlets_annual_v.png'\n",
    "fig.savefig(directory + now + filename, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centreline_theil_slopes(df, **kwargs):\n",
    "    \n",
    "    _var = kwargs.get('var', 'v')\n",
    "    _x = kwargs.get('x', 'mid_date')\n",
    "    _date_range = kwargs.get('date_range', (pd.Timestamp('1900-01-01'),\n",
    "                                            pd.Timestamp.now()))\n",
    "    _ddt_range = kwargs.get('ddt_range', ('0d', '30d'))\n",
    "    _mad = kwargs.get('mad', 3)\n",
    "    \n",
    "    _df = df.loc[df[_x].between(*_date_range)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((ds['date_dt'] > pd.Timedelta('335d')) & ((ds['date_dt'] <= pd.Timedelta('395d')))).compute()\n",
    "\n",
    "from scipy.stats.mstats import theilslopes\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = (ds.mid_date[idx] - ds.mid_date[idx].min()) / pd.Timedelta('365.25d')\n",
    "y = ds['v'][idx,50,50].compute()\n",
    "\n",
    "nan_idx = y.isnull()\n",
    "\n",
    "x = x[~nan_idx]\n",
    "y= y[~nan_idx]\n",
    "\n",
    "theil_result = theilslopes(y=y, x=x)\n",
    "lr_result = linregress(x=x, y=y)\n",
    "\n",
    "\n",
    "X = np.arange(0,30)\n",
    "theil_fit = (X * theil_result.slope) + theil_result.intercept\n",
    "lr_fit = (X * lr_result.slope) + lr_result.intercept\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y)\n",
    "\n",
    "ax.plot(X, theil_fit, c='r', label='theilslopes')\n",
    "ax.plot(X, lr_fit, c='g', label='lr')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8], nrows=5, ncols=3)\n",
    "# get_velocity.Plotters.date_dt_bars(V[13],\n",
    "#                                    ('1d','15d'),\n",
    "#                                    ax=ax,\n",
    "#                                    **{'vals':[5_000,1_000]})\n",
    "\n",
    "get_velocity.Plotters.rolling_median(V[13],\n",
    "                                     ('335d','395d'),\n",
    "                                     ax=ax,\n",
    "                                     ddt_bars=False,\n",
    "                                     **{'var': 'v',\n",
    "                                        'col': 'cumul_dist',\n",
    "                                        'window': '180d',\n",
    "                                        'vals':[1_000, 3_000, 5_000, 10_000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at underlying dodgy velocity images\n",
    "TODO look at GRIMpP and MEASUREs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- PN thinks that relative change is sufficient to *control* for variations in glacier geometry (read: width/size).\n",
    "- most interested in *relative* change of velocity over final few kilometers.\n",
    "    - i.e. \n",
    "\n",
    "- it all comes from the same raw processed v data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sites = gpd.read_file('../data/potential_study_sites_v1.geojson')\n",
    "study_sites = study_sites.loc[study_sites['notes'].isin(['yes', 'maybe'])]\n",
    "study_sites.reset_index(drop=True, inplace=True)\n",
    "study_sites_5k = study_sites.buffer(5_000).to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = imagery.get_annual_median_mosaic(\n",
    "    study_sites.loc[0,'geometry'],\n",
    "    buffer_dist=15_000,\n",
    "    src_crs=study_sites.crs,\n",
    "    target_crs=4326,\n",
    "    timeperiod='2023-01-01/2024-01-01',\n",
    "    months=[8,9],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xrs.multispectral.true_color(\n",
    "    *items.squeeze()\n",
    "    .transpose('band', 'y', 'x'))\n",
    " .plot.imshow(rgb='band')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "stackstac.stack(items, assets=['B04', 'B03', 'B02'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import dask.dataframe as da\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "# from dem_utils import ArcticDEM\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "# import utils\n",
    "import cartopy.crs as ccrs\n",
    "import shapely\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.enums import Resampling\n",
    "import seaborn as sns\n",
    "# import odc.geo.xr\n",
    "prj = ccrs.Stereographic(\n",
    "    central_latitude=90,\n",
    "    central_longitude=-45,\n",
    "    true_scale_latitude=70\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10210\n",
      "12040\n",
      "12513\n",
      "10361\n",
      "3093\n",
      "9377\n",
      "9554\n",
      "9248\n",
      "10347\n",
      "10476\n",
      "9154\n",
      "14207\n",
      "10709\n",
      "14309\n",
      "10337\n",
      "8218\n",
      "15506\n",
      "14308\n",
      "18675\n",
      "10815\n",
      "14296\n",
      "20422\n",
      "9514\n",
      "16229\n",
      "16856\n",
      "15138\n",
      "10947\n",
      "7377\n",
      "14816\n",
      "10803\n",
      "6528\n"
     ]
    }
   ],
   "source": [
    "dirs = glob('../data/id*')\n",
    "for d in dirs:\n",
    "    f = glob('elevation_sample*', root_dir=d)\n",
    "    if len(f)==0:\n",
    "        print(f'fuck: {d}')\n",
    "    else:\n",
    "        df = da.read_parquet(os.path.join(d, f[0]))\n",
    "        print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/id21_288157x_-930867y/'\n",
    "sec_path = os.path.join(directory, 'sec.zarr')\n",
    "dem_path = os.path.join(directory, 'stacked_coregd.zarr')\n",
    "mask_path = os.path.join(directory, 'stable_terrain_mask.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demote_coords_to_vars(ds: xr.Dataset,\n",
    "                        coords: str,\n",
    "                        var_name: str):\n",
    "    '''\n",
    "    messy onliner to for reorganizing dataset.\n",
    "    e.g. dataset with two variables: a (dims: x, y, t) and b (dims: x, y)\n",
    "    this function will convert it to a dataset with \n",
    "    dimensions x, y and add as many `a` variables as there dim `t` is long\n",
    "    '''\n",
    "    return xr.merge([\n",
    "        ds.drop_vars([coords, var_name]),\n",
    "        xr.merge(\n",
    "            [ds[var_name].isel({coords:i}).rename(ds[coords][i].item())\n",
    "            for i in range(len(ds[coords]))], compat='override').drop_vars(coords)]\n",
    "                    )\n",
    "\n",
    "def add_geom_mask(geom, buffer, ds):\n",
    "    # buffer geometry, with square ends\n",
    "    buff_geom = geom.buffer(200, cap_style=3)\n",
    "    \n",
    "    # empty array of same x, y dim shape as merged\n",
    "    arr = np.zeros((ds.sizes['y'], ds.sizes['x']))\n",
    "    \n",
    "    # rasterize\n",
    "    burned = rasterize(shapes=[(buff_geom, 1)],\n",
    "                       fill=0,\n",
    "                       out=arr,\n",
    "                       transform=ds.rio.transform())\n",
    "    \n",
    "    # merged rasterized with all other dataarrays\n",
    "    merged = xr.merge([ds, xr.DataArray(data=burned,\n",
    "                                        dims=['y','x'],\n",
    "                                        coords={'y': ds.y,\n",
    "                                                'x': ds.x}).rename('buffer_aoi')])\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def get_summary_df(site):\n",
    "    id = os.path.basename(site).split('_')[0][2:]\n",
    "    \n",
    "    cl_path = os.path.join(site, glob('*.geojson', root_dir=site)[0])\n",
    "    cl = gpd.read_file(cl_path)\n",
    "    where = cl.loc[0, 'where']\n",
    "    lake_land = cl.loc[0, 'lake_land']\n",
    "    \n",
    "    sec_path = os.path.join(site, 'sec.zarr')\n",
    "    dem_path = os.path.join(site, 'stacked_coregd.zarr')\n",
    "    mask_path = os.path.join(site, 'stable_terrain_mask.tif')\n",
    "    \n",
    "    _sec = xr.open_zarr(sec_path)\n",
    "    _sec = demote_coords_to_vars(_sec, 'result', 'sec')\n",
    "    \n",
    "    with xr.open_zarr(dem_path) as _dem:\n",
    "        _dem_median = _dem['z'].median(dim='time',\n",
    "                                       skipna=True).compute()\n",
    "    \n",
    "    _dem_median = _dem_median.rio.reproject_match(_sec,\n",
    "                                            resampling=Resampling.bilinear,\n",
    "                                            nodata=np.nan).rename('z_median')\n",
    "    # _dem_median = reproject_like(_dem_median, _sec).rename('z_median').compute()\n",
    "                \n",
    "    with rio.open_rasterio(mask_path).squeeze().drop_vars('band') as _mask:\n",
    "        mask_rprj = _mask.rio.reproject_match(_sec,\n",
    "                                              resampling=Resampling.bilinear,\n",
    "                                              nodata=0).rename('mask')\n",
    "\n",
    "    # _dem_median_mask = xr.where(mask_rprj == 0, _dem_median, np.nan)\n",
    "    # _sec_mask = xr.where(mask_rprj == 0, _sec, np.nan)\n",
    "    merged = xr.merge([_dem_median, _sec, mask_rprj],\n",
    "                      compat='override').compute()\n",
    "       \n",
    "    merged = add_geom_mask(cl.loc[0,'geometry'], 200, merged)\n",
    "        \n",
    "    ## take logical and of NOT stable terrain and centreline masks,\n",
    "    cl_mask = ((merged['mask'] != 1) & (merged['buffer_aoi'] == 1))\n",
    "\n",
    "    # set everything else to nan\n",
    "    cl_masked = xr.where(cl_mask, merged, np.nan)\n",
    "\n",
    "    # convert to dask dataframe\n",
    "    df = (cl_masked\n",
    "        .to_dask_dataframe()\n",
    "        .dropna()\n",
    "        .drop(columns='spatial_ref')\n",
    "        .reset_index())\n",
    "\n",
    "    # add additional meta\n",
    "    df['where'] = where\n",
    "    df['id'] = id\n",
    "    df['lake_land'] = lake_land\n",
    "\n",
    "    outpath = os.path.join(directory, 'elevation_sample.parquet')\n",
    "    print(f'exporting to {outpath}')\n",
    "    # return df, outpath\n",
    "    da.to_parquet(df=df, path=outpath, compute=True)\n",
    "    print('done')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>z_median</th>\n",
       "      <th>n</th>\n",
       "      <th>slope</th>\n",
       "      <th>intercept</th>\n",
       "      <th>low_slope</th>\n",
       "      <th>high_slope</th>\n",
       "      <th>mask</th>\n",
       "      <th>buffer_aoi</th>\n",
       "      <th>where</th>\n",
       "      <th>id</th>\n",
       "      <th>lake_land</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__null_dask_index__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311880</td>\n",
       "      <td>-2.492360e+06</td>\n",
       "      <td>-231300.0</td>\n",
       "      <td>294.565491</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.679076</td>\n",
       "      <td>301.207842</td>\n",
       "      <td>-1.863758</td>\n",
       "      <td>-1.473365</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>311881</td>\n",
       "      <td>-2.492360e+06</td>\n",
       "      <td>-231280.0</td>\n",
       "      <td>294.635681</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.586579</td>\n",
       "      <td>300.842696</td>\n",
       "      <td>-1.834412</td>\n",
       "      <td>-1.369480</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311882</td>\n",
       "      <td>-2.492360e+06</td>\n",
       "      <td>-231260.0</td>\n",
       "      <td>294.965149</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.699155</td>\n",
       "      <td>301.471282</td>\n",
       "      <td>-1.931409</td>\n",
       "      <td>-1.452984</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311883</td>\n",
       "      <td>-2.492360e+06</td>\n",
       "      <td>-231240.0</td>\n",
       "      <td>294.911652</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.586162</td>\n",
       "      <td>300.851831</td>\n",
       "      <td>-1.799268</td>\n",
       "      <td>-1.383337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>311884</td>\n",
       "      <td>-2.492360e+06</td>\n",
       "      <td>-231220.0</td>\n",
       "      <td>295.426117</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.487127</td>\n",
       "      <td>301.113956</td>\n",
       "      <td>-1.670903</td>\n",
       "      <td>-1.305947</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15133</th>\n",
       "      <td>399539</td>\n",
       "      <td>-2.493702e+06</td>\n",
       "      <td>-217440.0</td>\n",
       "      <td>651.276855</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-0.211007</td>\n",
       "      <td>652.174471</td>\n",
       "      <td>-0.403373</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15134</th>\n",
       "      <td>399540</td>\n",
       "      <td>-2.493702e+06</td>\n",
       "      <td>-217420.0</td>\n",
       "      <td>651.298889</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-0.212646</td>\n",
       "      <td>652.146090</td>\n",
       "      <td>-0.398980</td>\n",
       "      <td>0.040143</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15135</th>\n",
       "      <td>399541</td>\n",
       "      <td>-2.493702e+06</td>\n",
       "      <td>-217400.0</td>\n",
       "      <td>651.470581</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-0.215888</td>\n",
       "      <td>652.352541</td>\n",
       "      <td>-0.402447</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15136</th>\n",
       "      <td>399542</td>\n",
       "      <td>-2.493702e+06</td>\n",
       "      <td>-217380.0</td>\n",
       "      <td>651.750549</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.187849</td>\n",
       "      <td>652.504162</td>\n",
       "      <td>-0.388448</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15137</th>\n",
       "      <td>399543</td>\n",
       "      <td>-2.493702e+06</td>\n",
       "      <td>-217360.0</td>\n",
       "      <td>651.870117</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.142915</td>\n",
       "      <td>652.383943</td>\n",
       "      <td>-0.364000</td>\n",
       "      <td>0.133134</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>20</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15138 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index             y         x    z_median     n  \\\n",
       "__null_dask_index__                                                     \n",
       "0                    311880 -2.492360e+06 -231300.0  294.565491  72.0   \n",
       "1                    311881 -2.492360e+06 -231280.0  294.635681  72.0   \n",
       "2                    311882 -2.492360e+06 -231260.0  294.965149  72.0   \n",
       "3                    311883 -2.492360e+06 -231240.0  294.911652  73.0   \n",
       "4                    311884 -2.492360e+06 -231220.0  295.426117  73.0   \n",
       "...                     ...           ...       ...         ...   ...   \n",
       "15133                399539 -2.493702e+06 -217440.0  651.276855  91.0   \n",
       "15134                399540 -2.493702e+06 -217420.0  651.298889  91.0   \n",
       "15135                399541 -2.493702e+06 -217400.0  651.470581  91.0   \n",
       "15136                399542 -2.493702e+06 -217380.0  651.750549  90.0   \n",
       "15137                399543 -2.493702e+06 -217360.0  651.870117  90.0   \n",
       "\n",
       "                        slope   intercept  low_slope  high_slope  mask  \\\n",
       "__null_dask_index__                                                      \n",
       "0                   -1.679076  301.207842  -1.863758   -1.473365  -1.0   \n",
       "1                   -1.586579  300.842696  -1.834412   -1.369480  -1.0   \n",
       "2                   -1.699155  301.471282  -1.931409   -1.452984  -1.0   \n",
       "3                   -1.586162  300.851831  -1.799268   -1.383337  -1.0   \n",
       "4                   -1.487127  301.113956  -1.670903   -1.305947  -1.0   \n",
       "...                       ...         ...        ...         ...   ...   \n",
       "15133               -0.211007  652.174471  -0.403373    0.050258  -1.0   \n",
       "15134               -0.212646  652.146090  -0.398980    0.040143  -1.0   \n",
       "15135               -0.215888  652.352541  -0.402447    0.028028  -1.0   \n",
       "15136               -0.187849  652.504162  -0.388448    0.062024  -1.0   \n",
       "15137               -0.142915  652.383943  -0.364000    0.133134  -1.0   \n",
       "\n",
       "                     buffer_aoi      where  id lake_land  \n",
       "__null_dask_index__                                       \n",
       "0                           1.0  greenland  20      land  \n",
       "1                           1.0  greenland  20      land  \n",
       "2                           1.0  greenland  20      land  \n",
       "3                           1.0  greenland  20      land  \n",
       "4                           1.0  greenland  20      land  \n",
       "...                         ...        ...  ..       ...  \n",
       "15133                       1.0  greenland  20      land  \n",
       "15134                       1.0  greenland  20      land  \n",
       "15135                       1.0  greenland  20      land  \n",
       "15136                       1.0  greenland  20      land  \n",
       "15137                       1.0  greenland  20      land  \n",
       "\n",
       "[15138 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('../data/id20_-225808x_-2493072y/elevation_sample.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>z_median</th>\n",
       "      <th>n</th>\n",
       "      <th>slope</th>\n",
       "      <th>intercept</th>\n",
       "      <th>low_slope</th>\n",
       "      <th>high_slope</th>\n",
       "      <th>mask</th>\n",
       "      <th>buffer_aoi</th>\n",
       "      <th>where</th>\n",
       "      <th>id</th>\n",
       "      <th>lake_land</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__null_dask_index__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>399120</td>\n",
       "      <td>-927885.050054</td>\n",
       "      <td>293849.709892</td>\n",
       "      <td>371.822632</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.923722</td>\n",
       "      <td>377.357997</td>\n",
       "      <td>-0.990578</td>\n",
       "      <td>-0.878007</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400322</td>\n",
       "      <td>-927905.065288</td>\n",
       "      <td>293829.701579</td>\n",
       "      <td>374.228210</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.982879</td>\n",
       "      <td>380.062108</td>\n",
       "      <td>-1.061822</td>\n",
       "      <td>-0.918300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400323</td>\n",
       "      <td>-927905.065288</td>\n",
       "      <td>293849.709892</td>\n",
       "      <td>372.723389</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.960258</td>\n",
       "      <td>378.503309</td>\n",
       "      <td>-1.015531</td>\n",
       "      <td>-0.899485</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400324</td>\n",
       "      <td>-927905.065288</td>\n",
       "      <td>293869.718204</td>\n",
       "      <td>370.800812</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.920299</td>\n",
       "      <td>376.478685</td>\n",
       "      <td>-1.001954</td>\n",
       "      <td>-0.851485</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401523</td>\n",
       "      <td>-927925.080522</td>\n",
       "      <td>293789.684954</td>\n",
       "      <td>377.455170</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-1.040214</td>\n",
       "      <td>383.679459</td>\n",
       "      <td>-1.101891</td>\n",
       "      <td>-0.958327</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15501</th>\n",
       "      <td>817083</td>\n",
       "      <td>-934850.351469</td>\n",
       "      <td>280224.049044</td>\n",
       "      <td>876.999451</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.420907</td>\n",
       "      <td>878.372902</td>\n",
       "      <td>-0.492269</td>\n",
       "      <td>-0.349391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15502</th>\n",
       "      <td>817084</td>\n",
       "      <td>-934850.351469</td>\n",
       "      <td>280244.057357</td>\n",
       "      <td>876.509766</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.423840</td>\n",
       "      <td>877.795194</td>\n",
       "      <td>-0.501019</td>\n",
       "      <td>-0.363567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15503</th>\n",
       "      <td>817085</td>\n",
       "      <td>-934850.351469</td>\n",
       "      <td>280264.065669</td>\n",
       "      <td>875.957214</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.423825</td>\n",
       "      <td>877.241198</td>\n",
       "      <td>-0.499648</td>\n",
       "      <td>-0.357873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15504</th>\n",
       "      <td>818282</td>\n",
       "      <td>-934870.366703</td>\n",
       "      <td>280144.015794</td>\n",
       "      <td>879.260498</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.421975</td>\n",
       "      <td>880.525437</td>\n",
       "      <td>-0.492424</td>\n",
       "      <td>-0.357617</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15505</th>\n",
       "      <td>818283</td>\n",
       "      <td>-934870.366703</td>\n",
       "      <td>280164.024106</td>\n",
       "      <td>878.643311</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.415387</td>\n",
       "      <td>880.045577</td>\n",
       "      <td>-0.493440</td>\n",
       "      <td>-0.347257</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greenland</td>\n",
       "      <td>21</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index              y              x    z_median     n  \\\n",
       "__null_dask_index__                                                           \n",
       "0                    399120 -927885.050054  293849.709892  371.822632  27.0   \n",
       "1                    400322 -927905.065288  293829.701579  374.228210  27.0   \n",
       "2                    400323 -927905.065288  293849.709892  372.723389  27.0   \n",
       "3                    400324 -927905.065288  293869.718204  370.800812  27.0   \n",
       "4                    401523 -927925.080522  293789.684954  377.455170  27.0   \n",
       "...                     ...            ...            ...         ...   ...   \n",
       "15501                817083 -934850.351469  280224.049044  876.999451  74.0   \n",
       "15502                817084 -934850.351469  280244.057357  876.509766  74.0   \n",
       "15503                817085 -934850.351469  280264.065669  875.957214  74.0   \n",
       "15504                818282 -934870.366703  280144.015794  879.260498  74.0   \n",
       "15505                818283 -934870.366703  280164.024106  878.643311  74.0   \n",
       "\n",
       "                        slope   intercept  low_slope  high_slope  mask  \\\n",
       "__null_dask_index__                                                      \n",
       "0                   -0.923722  377.357997  -0.990578   -0.878007  -1.0   \n",
       "1                   -0.982879  380.062108  -1.061822   -0.918300  -1.0   \n",
       "2                   -0.960258  378.503309  -1.015531   -0.899485  -1.0   \n",
       "3                   -0.920299  376.478685  -1.001954   -0.851485  -1.0   \n",
       "4                   -1.040214  383.679459  -1.101891   -0.958327  -1.0   \n",
       "...                       ...         ...        ...         ...   ...   \n",
       "15501               -0.420907  878.372902  -0.492269   -0.349391  -1.0   \n",
       "15502               -0.423840  877.795194  -0.501019   -0.363567  -1.0   \n",
       "15503               -0.423825  877.241198  -0.499648   -0.357873  -1.0   \n",
       "15504               -0.421975  880.525437  -0.492424   -0.357617  -1.0   \n",
       "15505               -0.415387  880.045577  -0.493440   -0.347257  -1.0   \n",
       "\n",
       "                     buffer_aoi      where  id lake_land  \n",
       "__null_dask_index__                                       \n",
       "0                           1.0  greenland  21      land  \n",
       "1                           1.0  greenland  21      land  \n",
       "2                           1.0  greenland  21      land  \n",
       "3                           1.0  greenland  21      land  \n",
       "4                           1.0  greenland  21      land  \n",
       "...                         ...        ...  ..       ...  \n",
       "15501                       1.0  greenland  21      land  \n",
       "15502                       1.0  greenland  21      land  \n",
       "15503                       1.0  greenland  21      land  \n",
       "15504                       1.0  greenland  21      land  \n",
       "15505                       1.0  greenland  21      land  \n",
       "\n",
       "[15506 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_parquet('../data/id21_288157x_-930867y/elevation_sample.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2, memory_limit='8G')\n",
    "client = cluster.get_client()\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary_df(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = xr.open_zarr(os.path.join(directory, 'sec.zarr'))\n",
    "dem = xr.open_zarr(os.path.join(directory, 'stacked_coregd.zarr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(subplot_kw={'projection':prj}, ncols=2, sharex=True, sharey=True)\n",
    "\n",
    "dem_median.plot(ax=axs[0])\n",
    "sec['sec'].sel(result='slope').plot(ax=axs[1], robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fix centreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fixing centrelines\n",
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "sites = glob('../data/id*')\n",
    "for s in sites:\n",
    "    id = int(os.path.basename(s).split('_')[0].replace('id',''))\n",
    "    json_cl_path = glob('*.geojson', root_dir=s)\n",
    "    json_cl = gpd.read_file(os.path.join(s, json_cl_path[0])).loc[0,'geometry']\n",
    "    old_cntr = json_cl.centroid\n",
    "    cl_new = centrelines.loc[id, 'geometry']\n",
    "    new_cntr = cl_new.centroid\n",
    "    assert cl_new.equals(json_cl), 'uh oh they are different'\n",
    "    \n",
    "    zarr_files = glob('*.zarr', root_dir=s)\n",
    "    for zarr in zarr_files:\n",
    "        with xr.open_zarr(os.path.join(s, zarr)) as ds:\n",
    "            zarr_cl = wkt.loads(ds.attrs['centreline'])\n",
    "            if zarr_cl.equals(cl_new):\n",
    "                pass\n",
    "                # print(f'all good in {zarr}')\n",
    "                print(s, zarr, ds.dims)\n",
    "            else:\n",
    "                print('fuck')\n",
    "                # # print(f'distance: {zarr_cl.centroid.distance(new_cntr):.2f}')\n",
    "                # same_ends = zarr_cl.boundary.geoms[-1].equals(cl_new.boundary.geoms[-1])\n",
    "                # if same_ends:\n",
    "                #     print(f'the upglacier ends are the same: {same_ends} - overwriting attrs')\n",
    "                #     ds.attrs.update({'centreline': cl_new.wkt})\n",
    "                #     ds.to_zarr(os.path.join(s, zarr), mode='a')\n",
    "                # else:\n",
    "                #     print('not a clue what to do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '../data/id17_-167858x_-3142959y/sec.zarr/'\n",
    "with xr.open_zarr(fpath) as ds:\n",
    "    geom = wkt.loads(ds.attrs['centreline'])\n",
    "    arr = np.zeros(ds['n'].shape)\n",
    "    burned = rasterize(shapes=[(geom.buffer(200, cap_style=3), 1)],\n",
    "                       fill=0,\n",
    "                       out=arr,\n",
    "                       transform=ds.rio.transform())\n",
    "    merged = xr.merge([ds, xr.DataArray(data=burned,\n",
    "                                        dims=['y','x'],\n",
    "                                        coords={'y': ds.y,\n",
    "                                                'x': ds.x}).rename('buffer_aoi')]\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = xr.where(merged['buffer_aoi']==1, merged['sec'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked.sel(result='slope').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer geometry, with square ends\n",
    "buff_geom = cl.loc[0,'geometry'].buffer(200, cap_style=3)\n",
    "\n",
    "# empty array of same x, y dim shape as merged\n",
    "arr = np.zeros(merged['z_median'].shape)\n",
    "\n",
    "# rasterize\n",
    "burned = rasterize(shapes=[(buff_geom, 1)],\n",
    "                fill=0,\n",
    "                out=arr,\n",
    "                transform=merged.rio.transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection':prj})\n",
    "ds['sec'].sel(result='slope').plot(ax=ax, robust=True, cmap='RdBu')\n",
    "ax.plot(*wkt.loads(ds.attrs['centreline']).coords.xy, c='k', ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = da.concat([da.read_parquet(f) for f in glob('../data/**/elevation_sample.parquet')])\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.compute()\n",
    "\n",
    "# because this one in iceland is probably better described as lake terminating\n",
    "# df.loc[df['id']=='29', 'lake_land'] = 'lake'\n",
    "\n",
    "df['z_bins'] = pd.cut(df['z_median'], np.arange(-50,2000,100))\n",
    "df['mid_bin'] = df['z_bins'].apply(lambda x: int(x.mid))\n",
    "groups = df.groupby(['where', 'lake_land'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.catplot(data=df.loc[df['where']=='greenland'],\n",
    "                 x='mid_bin',\n",
    "                 y='slope',\n",
    "                 hue='lake_land',\n",
    "                 col='id',\n",
    "                 col_wrap=5,\n",
    "                 fliersize=0.5,\n",
    "                 kind='box',\n",
    "                 )\n",
    "\n",
    "fg.set(ylim=(-10,10))\n",
    "fg.set_xticklabels(rotation=30)\n",
    "fg.map(plt.axhline, y=0, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = xr.open_zarr('../data/id29_1368245x_-2521726y/sec.zarr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_stack = ArcticDEM.sample_along_line('../data/id29_1368245x_-2521726y/stacked_coregd.zarr/')\n",
    "sampled_sec = ArcticDEM.sample_along_line('../data/id29_1368245x_-2521726y/sec.zarr/')\n",
    "sampled_sec = demote_coords_to_vars(sampled_sec, 'result', 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_stack.time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sampled_sec['slope'].plot(ax=ax)\n",
    "ax.axhline(0, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (np.abs(sampled['median_after']) < 1) & (sampled['nmad_after'] < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.get_cmap('viridis', len(sampled.time)).colors\n",
    "\n",
    "fig = plt.figure(figsize=[6,6])\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_prop_cycle(cycler(color=colors))\n",
    "_ = sampled['z'].sel(time=idx).plot(hue='time', ax=ax, add_legend=False, lw=0.5)\n",
    "ax.set_ylim(50, 900)\n",
    "ax.set_xlim(0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.catplot(data=df.loc[df['where']=='iceland'],\n",
    "                 x='mid_bin',\n",
    "                 y='slope',\n",
    "                 hue='lake_land',\n",
    "                 col='id',\n",
    "                 col_wrap=5,\n",
    "                 fliersize=0.5,\n",
    "                 kind='box',\n",
    "                 )\n",
    "\n",
    "fg.set(ylim=(-10,10))\n",
    "fg.set_xticklabels(rotation=30)\n",
    "fg.map(plt.axhline, y=0, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrelines.reset_index().loc[centrelines['where']=='iceland'].explore(tiles = 'https://api.maptiler.com/tiles/satellite-v2/{z}/{x}/{y}.jpg?key=qXXaw6q8a36GQNC8fUDj',\n",
    "                                                         attr='asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic([['greenland_lake', 'iceland_lake'],\n",
    "                               ['greenland_land', 'iceland_land']],\n",
    "                              sharex=True, sharey=True)\n",
    "\n",
    "for where, lake_land in groups.groups:\n",
    "    axes = f'{where}_{lake_land}'\n",
    "    _tmp = groups.get_group((where, lake_land))\n",
    "    \n",
    "    _tmp = _tmp.loc[_tmp['slope'].abs() < 20]\n",
    "    \n",
    "    axs[axes].hexbin(_tmp['z_median'], _tmp['slope'], gridsize=(20,20), extent=(-50,1550,-10,10), cmap='Blues')\n",
    "    \n",
    "    # sns.kdeplot(_tmp, x='z_median', y='slope', ax=axs[axes])\n",
    "    \n",
    "    axs[axes].set_title(axes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sec field and count of arctic DEMs for each site\n",
    "\n",
    "sites = glob('../data/id*')\n",
    "for site in sites:\n",
    "\n",
    "    id = os.path.basename(site).split('_')[0][2:]\n",
    "    sec = xr.open_zarr(site + '/sec.zarr')\n",
    "    dem = xr.open_zarr(site + '/stacked_coregd.zarr')\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=2,\n",
    "                            subplot_kw={'projection':prj})\n",
    "\n",
    "    sec['sec'].sel(result='slope').plot(ax=axs[0],\n",
    "                                        robust=True,\n",
    "                                        cmap='RdBu',\n",
    "                                        cbar_kwargs={'shrink': 0.6,\n",
    "                                                     'label': '(m/yr)'})\n",
    "\n",
    "    sec['n'].plot(ax=axs[1],\n",
    "                  cbar_kwargs={'shrink':0.6,\n",
    "                               'label': 'count'})\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.plot(*wkt.loads(sec.attrs['centreline']).coords.xy, c='k', ls=':')\n",
    "\n",
    "    axs[0].set_title(f'#{id} surface elevation change')\n",
    "    axs[1].set_title(f'#{id}: count of ArcticDEMs')\n",
    "    \n",
    "    # fig.savefig(site + '/sec_result.png', dpi=600, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = glob('../data/id*')\n",
    "\n",
    "colors = {'lake': 'tab:blue',\n",
    "          'land': 'tab:green'}\n",
    "\n",
    "markers = {'greenland': 'o',\n",
    "           'iceland': '+'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for site in tqdm(sites):\n",
    "    \n",
    "    id = os.path.basename(site).split('_')[0][2:]\n",
    "    \n",
    "    cl_path = os.path.join(site, glob('*.geojson', root_dir=site)[0])\n",
    "    cl = gpd.read_file(cl_path)\n",
    "    \n",
    "    where = cl.loc[0, 'where']\n",
    "    lake_land = cl.loc[0, 'lake_land']\n",
    "    \n",
    "    sec_path = os.path.join(site, 'sec.zarr')\n",
    "    dem_path = os.path.join(site, 'stacked_coregd.zarr')\n",
    "    \n",
    "    sampled_sec = ArcticDEM.sample_along_line(sec_path)\n",
    "    sampled_sec = demote_coords_to_vars(sampled_sec, 'result', 'sec')\n",
    "    \n",
    "    sampled_dem = ArcticDEM.sample_along_line(dem_path, var='z')\n",
    "    sampled_dem = sampled_dem['z'].median(dim='time').drop_vars('spatial_ref')\n",
    "    \n",
    "    sample = xr.merge([sampled_sec,\n",
    "                       sampled_dem])\n",
    "    \n",
    "    df = sample.to_dataframe()\n",
    "    \n",
    "    df['where'] = where\n",
    "    df['lake_land'] = lake_land\n",
    "    df['id'] = id\n",
    "    \n",
    "    dfs.append(df)\n",
    "    \n",
    "    # sample.plot.scatter(x='z',\n",
    "    #                     y='slope',\n",
    "    #                     color=colors[lake_land],\n",
    "    #                     marker=markers[where],\n",
    "    #                     ax=ax\n",
    "    #                     )\n",
    "\n",
    "dataframe = da.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic([['greenland'],['iceland']], sharex=True, sharey=True)\n",
    "\n",
    "directory = '../data/id5_-226289x_-2968847y/'\n",
    "for directory in glob('../data/id*'):\n",
    "    id = directory.split('id')[1].split('_')[0]\n",
    "    \n",
    "    centreline_filepath = glob('*.geojson', root_dir=directory)\n",
    "    gdf = gpd.read_file(os.path.join(directory, centreline_filepath[0]))\n",
    "    where = gdf.loc[0, 'where']\n",
    "    \n",
    "    sec_filepath = glob('sec.zarr', root_dir=directory)\n",
    "    sec_filepath = os.path.join(directory, sec_filepath[0])\n",
    "    z_filepath = glob('stacked*', root_dir=directory)\n",
    "    z_filepath = os.path.join(directory, z_filepath[0])\n",
    "    \n",
    "    sec_along_line = sample_sec_along_line(sec_filepath)\n",
    "    z_along_line = sample_sec_along_line(z_filepath, var='z')\n",
    "    merged = xr.merge([sec_along_line.sel(result='slope').drop_vars('spatial_ref'),\n",
    "                    z_along_line.median(dim='time')])\n",
    "\n",
    "    merged[['z', 'sec']].to_dataframe().sort_values(by='z').plot(x='z', y='sec', label=id, ax=axs[where])\n",
    "    \n",
    "axs['greenland'].legend(fontsize=8, ncols=3, frameon=False, loc='upper right')\n",
    "axs['iceland'].legend(fontsize=8, ncols=2, frameon=False)\n",
    "\n",
    "axs['greenland'].set_title('greenland')\n",
    "axs['iceland'].set_title('iceland')\n",
    "\n",
    "axs['iceland'].set_xlabel('elevation (m)')\n",
    "axs['iceland'].set_ylabel('sec (m/yr)')\n",
    "axs['greenland'].set_ylabel('sec (m/yr)')\n",
    "\n",
    "# fig.savefig('../results/elevation_change/sec_against_z.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directory to centrelines geojson\n",
    "centrelines = gpd.read_file('../data/streams_v3.geojson')\n",
    "centrelines['directory'] = pd.Series()\n",
    "for line in centrelines.itertuples():\n",
    "    cntr = line.geometry.centroid\n",
    "    centrelines.loc[line.Index, 'directory'] = f'../data/id{line.Index}_{cntr.x:.0f}x_{cntr.y:.0f}y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(ds, id, ax, plot_err=False):\n",
    "    \n",
    "    ds['sec'].sel(result='slope').plot(ax=ax, label=id)\n",
    "    if plot_err:\n",
    "        ax.fill_between(\n",
    "            x=ds.cumulative_distance,\n",
    "            y1=ds['sec'].sel(result='high_slope').data,\n",
    "            y2=ds['sec'].sel(result='low_slope').data,\n",
    "            color='lightgrey')\n",
    "    ax.axhline(0, c='grey', lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "from adjustText import adjust_text\n",
    "from cycler import cycler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = 'greenland'\n",
    "\n",
    "colors = plt.get_cmap('tab20').colors\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "\n",
    "ax.set_prop_cycle(cycler(color=colors))\n",
    "\n",
    "axmap = fig.add_subplot(1,2,2, projection=prj)\n",
    "axmap.add_feature(cfeature.COASTLINE, edgecolor='lightgrey')\n",
    "centrelines.loc[centrelines['where']==where].plot(ax=axmap, color='k')\n",
    "gl = axmap.gridlines(crs=ccrs.PlateCarree(),\n",
    "                     draw_labels=True,\n",
    "                     y_inline=False)\n",
    "gl.rotate_labels=False\n",
    "\n",
    "gl.bottom_labels=True\n",
    "gl.left_labels=True\n",
    "gl.top_labels=False\n",
    "gl.right_labels=False\n",
    "gl.ylabel_style = {'rotation': 90}\n",
    "\n",
    "\n",
    "texts = []\n",
    "for i, row in enumerate(centrelines.loc[centrelines['where'] == where].itertuples()):\n",
    "    \n",
    "    sec_file = glob('sec.zarr', root_dir=row.directory)\n",
    "    assert len(sec_file) == 1, 'not enough / too many files'\n",
    "    sec_file_path = os.path.join(row.directory, sec_file[0])\n",
    "    \n",
    "    sampled = ArcticDEM.sample_along_line(sec_file_path)\n",
    "    \n",
    "    plot_result(sampled, row.Index, ax)\n",
    "    \n",
    "    \n",
    "    text = axmap.annotate(\n",
    "        text=row.Index,\n",
    "        xy=row.geometry.centroid.coords[0],\n",
    "        c=colors[i],\n",
    "        path_effects=[path_effects.withSimplePatchShadow(shadow_rgbFace='lightgrey',\n",
    "                                                                 alpha=0.9,\n",
    "                                                                 offset=(1,-1))])\n",
    "    texts.append(text)\n",
    "    \n",
    "_ = adjust_text(texts)\n",
    "\n",
    "# ax.legend(ncols=2, frameon=False)\n",
    "ax.set_title(None)\n",
    "ax.set_ylabel('surface elevation change (m/yr)')\n",
    "ax.set_xlabel('distance from terminus (km)')\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "axmap.set_axis_off()\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax.set_title(where)\n",
    "ax.set_xlim(right=10.4)\n",
    "\n",
    "fig.savefig(f'../results/elevation_change/{where}_sec.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, subplot_kw={'projection':prj})\n",
    "\n",
    "with LocalCluster() as c, c.get_client() as cli:\n",
    "    with xr.open_dataset('../data/id9_484789x_-1406074y/sec.zarr/',\n",
    "                         engine='zarr') as ds:\n",
    "        # counts = ds['z'].isnull().sum(dim=['x', 'y'])\n",
    "        ds['sec'].sel(result='slope').plot(robust=True, ax=axs[0], cbar_kwargs={'shrink':0.5})\n",
    "        ds['n'].plot(ax=axs[1], cbar_kwargs={'shrink':0.5})\n",
    "        cl = wkt.loads(ds.attrs['centreline'])    \n",
    "\n",
    "for ax in axs:\n",
    "    ax.plot(*cl.coords.xy, c='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_stat(df, stat, ax):\n",
    "    # df = get_meta_df(d)\n",
    "    after = f'{stat}_after'\n",
    "    before = f'{stat}_before'\n",
    "    for row in df.iterrows():\n",
    "        # print(row[0])\n",
    "        ax.annotate(\"\",\n",
    "                    xy=(row[1]['to_reg_acqdate1'], row[1][after]),\n",
    "                    xytext=(row[1]['to_reg_acqdate1'], row[1][before]),\n",
    "                    arrowprops=dict(arrowstyle='->'))\n",
    "    \n",
    "    minx, maxx = df['to_reg_acqdate1'].agg(['min','max'])\n",
    "    delta = pd.Timedelta('90d')\n",
    "    ax.set_xlim(minx-delta, maxx+delta)\n",
    "    ax.set_ylim(*df[[after, before]].melt()['value'].agg(['min','max']))\n",
    "    \n",
    "    ax.axhline(0, c='lightgrey', lw=0.5)\n",
    "    ax.axvline(df.ref_acqdate1.unique()[0], ls=':', c='k')\n",
    "    ax.set_ylabel(f'{stat} (m)')\n",
    "    for label in ax.get_xticklabels(which='major'):\n",
    "        label.set(rotation=30, horizontalalignment='center')\n",
    "\n",
    "def plot_coreg(df, ax):\n",
    "    # df = get_meta_df(d)\n",
    "    \n",
    "    plot_df = df[['median_after','median_before','nmad_after','nmad_before']].melt()\n",
    "    plot_df['when'] = plot_df['variable'].str.split('_').apply(lambda x: x[1])\n",
    "    plot_df['variable'] = plot_df['variable'].str.split('_').apply(lambda x: x[0])\n",
    "    sns.violinplot(data=plot_df,\n",
    "                   x='variable',\n",
    "                   y='value',\n",
    "                   hue='when',\n",
    "                   palette=sns.palettes.color_palette('colorblind')[-2:],\n",
    "                   hue_order=['before','after'],\n",
    "                   ax=ax)\n",
    "    ax.set_ylabel('metres')\n",
    "    ax.set_xlabel(None)\n",
    "    ax.axhline(0, c='lightgrey', lw=0.5, zorder=0)\n",
    "    sns.move_legend(ax, loc='best', title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/id8_607229x_-1847482y/'\n",
    "file = glob('stack*', root_dir=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach = False\n",
    "\n",
    "if beach:\n",
    "    with xr.open_dataset(os.path.join(directory, file[0]), engine='zarr') as ds:\n",
    "        2+2\n",
    "else:\n",
    "    with rio.open_rasterio('../data/id0_-138892x_-3197992y/padded_SETSM_s2s041_W1W1_20180709_10200100727D6100_1020010076EA9B00_2m_lsf_seg1.tif') as ds:\n",
    "        3+3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(os.path.join(directory, file[0]), engine='zarr')['z'].rio.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd\n",
    "# import itslive\n",
    "import geopandas as gpd\n",
    "# from shapely.geometry import Polygon\n",
    "# from shapely import box\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.collections import LineCollection\n",
    "# from matplotlib.dates import date2num, DateFormatter, YearLocator\n",
    "# import seaborn as sns\n",
    "# import xrspatial as xrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import importlib\n",
    "# import imagery\n",
    "import utils\n",
    "import velocity_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = importlib.reload(utils)\n",
    "# _ = importlib.reload(velocity_helpers)\n",
    "# _ = importlib.reload(imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in lines, and lazily get velocity cubes, centrelines, and robust trends\n",
    "lines = gpd.read_file('../data/streams_v2.geojson').to_crs(3413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = {}\n",
    "failed = []\n",
    "for row in tqdm(lines.sample(3).itertuples()):\n",
    "    print(f'working on #{row.Index}')\n",
    "    try:\n",
    "        V[row.Index] = velocity_helpers.CentreLiner(\n",
    "            geo=row.geometry,\n",
    "            buff_dist=500,\n",
    "            index=row.Index,\n",
    "            filter_cube=False,\n",
    "            get_robust_trend=True,\n",
    "            get_annual_median=False,\n",
    "            get_rgb=False,\n",
    "            )\n",
    "    except Exception as e:\n",
    "        failed.append((row.Index, e))\n",
    "        print(f'#{row.Index} did not work because\\n{e}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8],\n",
    "                        nrows=2,\n",
    "                        ncols=4,\n",
    "                        sharex=True,\n",
    "                        sharey=True)\n",
    "\n",
    "for k_v, ax in zip(V.items(), axs.flat):\n",
    "    k, v = k_v\n",
    "    velocity_helpers.Plotters.rolling_median(v,\n",
    "                                             ax=ax,\n",
    "                                         **{'var': 'v',\n",
    "                                            'ddt_range': ('335d','395d'),\n",
    "                                            'ddt_bars': False,\n",
    "                                            'col': 'cumul_dist',\n",
    "                                            'window': '90d',\n",
    "                                            'vals':[500, 1_000, 3_000, 5_000]\n",
    "                                            })\n",
    "    _point = utils.shapely_reprojector(v.point, 3413, 4326)\n",
    "    \n",
    "    ax.set_title(f'#{k}: {_point.y:.2f}N {_point.x:.2f}W\\n{lines.loc[k,\"name\"]}')\n",
    "    ax.minorticks_off()\n",
    "\n",
    "# axs.flat[-2].remove()\n",
    "axs.flat[-1].remove()\n",
    "\n",
    "now = pd.Timestamp.now().strftime('%y%m%d_%H%M')+ '_'\n",
    "directory = '../../GitHub/diary/journal_figures'\n",
    "filename = 'iceland_outlets_annual_v.png'\n",
    "fig.savefig(directory + now + filename, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centreline_theil_slopes(df, **kwargs):\n",
    "    \n",
    "    _var = kwargs.get('var', 'v')\n",
    "    _x = kwargs.get('x', 'mid_date')\n",
    "    _date_range = kwargs.get('date_range', (pd.Timestamp('1900-01-01'),\n",
    "                                            pd.Timestamp.now()))\n",
    "    _ddt_range = kwargs.get('ddt_range', ('0d', '30d'))\n",
    "    _mad = kwargs.get('mad', 3)\n",
    "    \n",
    "    _df = df.loc[df[_x].between(*_date_range)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((ds['date_dt'] > pd.Timedelta('335d')) & ((ds['date_dt'] <= pd.Timedelta('395d')))).compute()\n",
    "\n",
    "from scipy.stats.mstats import theilslopes\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = (ds.mid_date[idx] - ds.mid_date[idx].min()) / pd.Timedelta('365.25d')\n",
    "y = ds['v'][idx,50,50].compute()\n",
    "\n",
    "nan_idx = y.isnull()\n",
    "\n",
    "x = x[~nan_idx]\n",
    "y= y[~nan_idx]\n",
    "\n",
    "theil_result = theilslopes(y=y, x=x)\n",
    "lr_result = linregress(x=x, y=y)\n",
    "\n",
    "\n",
    "X = np.arange(0,30)\n",
    "theil_fit = (X * theil_result.slope) + theil_result.intercept\n",
    "lr_fit = (X * lr_result.slope) + lr_result.intercept\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y)\n",
    "\n",
    "ax.plot(X, theil_fit, c='r', label='theilslopes')\n",
    "ax.plot(X, lr_fit, c='g', label='lr')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15,8], nrows=5, ncols=3)\n",
    "# get_velocity.Plotters.date_dt_bars(V[13],\n",
    "#                                    ('1d','15d'),\n",
    "#                                    ax=ax,\n",
    "#                                    **{'vals':[5_000,1_000]})\n",
    "\n",
    "get_velocity.Plotters.rolling_median(V[13],\n",
    "                                     ('335d','395d'),\n",
    "                                     ax=ax,\n",
    "                                     ddt_bars=False,\n",
    "                                     **{'var': 'v',\n",
    "                                        'col': 'cumul_dist',\n",
    "                                        'window': '180d',\n",
    "                                        'vals':[1_000, 3_000, 5_000, 10_000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at underlying dodgy velocity images\n",
    "TODO look at GRIMpP and MEASUREs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- PN thinks that relative change is sufficient to *control* for variations in glacier geometry (read: width/size).\n",
    "- most interested in *relative* change of velocity over final few kilometers.\n",
    "    - i.e. \n",
    "\n",
    "- it all comes from the same raw processed v data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sites = gpd.read_file('../data/potential_study_sites_v1.geojson')\n",
    "study_sites = study_sites.loc[study_sites['notes'].isin(['yes', 'maybe'])]\n",
    "study_sites.reset_index(drop=True, inplace=True)\n",
    "study_sites_5k = study_sites.buffer(5_000).to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = imagery.get_annual_median_mosaic(\n",
    "    study_sites.loc[0,'geometry'],\n",
    "    buffer_dist=15_000,\n",
    "    src_crs=study_sites.crs,\n",
    "    target_crs=4326,\n",
    "    timeperiod='2023-01-01/2024-01-01',\n",
    "    months=[8,9],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xrs.multispectral.true_color(\n",
    "    *items.squeeze()\n",
    "    .transpose('band', 'y', 'x'))\n",
    " .plot.imshow(rgb='band')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "stackstac.stack(items, assets=['B04', 'B03', 'B02'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
